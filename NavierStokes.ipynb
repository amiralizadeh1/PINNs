{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa8SqNKxcz7hRtsJzW+GKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amiralizadeh1/PINNs/blob/master/NavierStokes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_omraXY59E0M",
        "outputId": "f94d719c-22fa-45a4-e3e8-7f0f409e9f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 41 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (2.0.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 60.9 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.3.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.50.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow==1.14.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__) #just the make sure the correct version of tf (i.e. 1) is installed."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjAYl-yU9Kmq",
        "outputId": "6e9c0c65-d507-4d5a-c7e7-9fc51f7a9cc2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/Utilities') #upload utilities folder to your google drive before running the lines\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "import time\n",
        "from itertools import product, combinations\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "from plotting import newfig, savefig\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "class PhysicsInformedNN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, x, y, t, u, v, layers):\n",
        "        \n",
        "        X = np.concatenate([x, y, t], 1)\n",
        "        \n",
        "        self.lb = X.min(0)\n",
        "        self.ub = X.max(0)\n",
        "                \n",
        "        self.X = X\n",
        "        \n",
        "        self.x = X[:,0:1]\n",
        "        self.y = X[:,1:2]\n",
        "        self.t = X[:,2:3]\n",
        "        \n",
        "        self.u = u\n",
        "        self.v = v\n",
        "        \n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NN\n",
        "        self.weights, self.biases = self.initialize_NN(layers)        \n",
        "        \n",
        "        # Initialize parameters\n",
        "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
        "        self.lambda_2 = tf.Variable([0.0], dtype=tf.float32)\n",
        "        \n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
        "        self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]])\n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
        "        \n",
        "        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
        "        self.v_tf = tf.placeholder(tf.float32, shape=[None, self.v.shape[1]])\n",
        "        \n",
        "        self.u_pred, self.v_pred, self.p_pred, self.f_u_pred, self.f_v_pred = self.net_NS(self.x_tf, self.y_tf, self.t_tf)\n",
        "        \n",
        "        self.loss = tf.reduce_sum(tf.square(self.u_tf - self.u_pred)) + \\\n",
        "                    tf.reduce_sum(tf.square(self.v_tf - self.v_pred)) + \\\n",
        "                    tf.reduce_sum(tf.square(self.f_u_pred)) + \\\n",
        "                    tf.reduce_sum(tf.square(self.f_v_pred))\n",
        "                    \n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 50000,\n",
        "                                                                           'maxfun': 50000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
        "        # learn more about the options: docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html\n",
        "        \n",
        "        \n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)        \n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]        \n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "    \n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "        \n",
        "    def net_NS(self, x, y, t):\n",
        "        lambda_1 = self.lambda_1\n",
        "        lambda_2 = self.lambda_2\n",
        "        \n",
        "        psi_and_p = self.neural_net(tf.concat([x,y,t], 1), self.weights, self.biases)\n",
        "        psi = psi_and_p[:,0:1]\n",
        "        p = psi_and_p[:,1:2]\n",
        "        \n",
        "        u = tf.gradients(psi, y)[0]\n",
        "        v = -tf.gradients(psi, x)[0]  \n",
        "        \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_y = tf.gradients(u, y)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        u_yy = tf.gradients(u_y, y)[0]\n",
        "        \n",
        "        v_t = tf.gradients(v, t)[0]\n",
        "        v_x = tf.gradients(v, x)[0]\n",
        "        v_y = tf.gradients(v, y)[0]\n",
        "        v_xx = tf.gradients(v_x, x)[0]\n",
        "        v_yy = tf.gradients(v_y, y)[0]\n",
        "        \n",
        "        p_x = tf.gradients(p, x)[0]\n",
        "        p_y = tf.gradients(p, y)[0]\n",
        "\n",
        "        f_u = u_t + lambda_1*(u*u_x + v*u_y) + p_x - lambda_2*(u_xx + u_yy) \n",
        "        f_v = v_t + lambda_1*(u*v_x + v*v_y) + p_y - lambda_2*(v_xx + v_yy)\n",
        "        \n",
        "        return u, v, p, f_u, f_v\n",
        "    \n",
        "    def callback(self, loss, lambda_1, lambda_2):\n",
        "        print('Loss: %.3e, l1: %.3f, l2: %.5f' % (loss, lambda_1, lambda_2))\n",
        "      \n",
        "    def train(self, nIter): \n",
        "\n",
        "        tf_dict = {self.x_tf: self.x, self.y_tf: self.y, self.t_tf: self.t,\n",
        "                   self.u_tf: self.u, self.v_tf: self.v}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(nIter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "### the program gets stuck in this loop. We will find a way out later on to see the final results.\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                lambda_1_value = self.sess.run(self.lambda_1)\n",
        "                lambda_2_value = self.sess.run(self.lambda_2)\n",
        "                print('It: %d, Loss: %.3e, l1: %.3f, l2: %.5f, Time: %.2f' % \n",
        "                      (it, loss_value, lambda_1_value, lambda_2_value, elapsed))\n",
        "                start_time = time.time()\n",
        "            \n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict = tf_dict,\n",
        "                                fetches = [self.loss, self.lambda_1, self.lambda_2],\n",
        "                                loss_callback = self.callback)\n",
        "            \n",
        "    \n",
        "    def predict(self, x_star, y_star, t_star):\n",
        "        \n",
        "        tf_dict = {self.x_tf: x_star, self.y_tf: y_star, self.t_tf: t_star}\n",
        "        \n",
        "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
        "        v_star = self.sess.run(self.v_pred, tf_dict)\n",
        "        p_star = self.sess.run(self.p_pred, tf_dict)\n",
        "        \n",
        "        return u_star, v_star, p_star\n",
        "\n",
        "def plot_solution(X_star, u_star, index):\n",
        "    \n",
        "    lb = X_star.min(0)\n",
        "    ub = X_star.max(0)\n",
        "    nn = 200\n",
        "    x = np.linspace(lb[0], ub[0], nn)\n",
        "    y = np.linspace(lb[1], ub[1], nn)\n",
        "    X, Y = np.meshgrid(x,y)\n",
        "    \n",
        "    U_star = griddata(X_star, u_star.flatten(), (X, Y), method='cubic')\n",
        "    \n",
        "    plt.figure(index)\n",
        "    plt.pcolor(X,Y,U_star, cmap = 'jet')\n",
        "    plt.colorbar()\n",
        "    \n",
        "    \n",
        "def axisEqual3D(ax):\n",
        "    extents = np.array([getattr(ax, 'get_{}lim'.format(dim))() for dim in 'xyz'])\n",
        "    sz = extents[:,1] - extents[:,0]\n",
        "    centers = np.mean(extents, axis=1)\n",
        "    maxsize = max(abs(sz))\n",
        "    r = maxsize/4\n",
        "    for ctr, dim in zip(centers, 'xyz'):\n",
        "        getattr(ax, 'set_{}lim'.format(dim))(ctr - r, ctr + r)\n",
        "        \n",
        "        \n",
        "if __name__ == \"__main__\": \n",
        "      \n",
        "    #N_train = 5000\n",
        "    N_train = 500\n",
        "    \n",
        "    layers = [3, 20, 20, 20, 20, 20, 20, 20, 20, 2]\n",
        "\n",
        "    # Load Data\n",
        "    data = scipy.io.loadmat('/content/drive/MyDrive/Data/cylinder_nektar_wake.mat')\n",
        "           \n",
        "    U_star = data['U_star'] # N x 2 x T\n",
        "    P_star = data['p_star'] # N x T\n",
        "    t_star = data['t'] # T x 1\n",
        "    X_star = data['X_star'] # N x 2\n",
        "    \n",
        "    N = X_star.shape[0]\n",
        "    T = t_star.shape[0]\n",
        "    \n",
        "    # Rearrange Data \n",
        "    XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
        "    YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
        "    TT = np.tile(t_star, (1,N)).T # N x T\n",
        "    \n",
        "    UU = U_star[:,0,:] # N x T\n",
        "    VV = U_star[:,1,:] # N x T\n",
        "    PP = P_star # N x T\n",
        "    \n",
        "    x = XX.flatten()[:,None] # NT x 1\n",
        "    y = YY.flatten()[:,None] # NT x 1\n",
        "    t = TT.flatten()[:,None] # NT x 1\n",
        "    \n",
        "    u = UU.flatten()[:,None] # NT x 1\n",
        "    v = VV.flatten()[:,None] # NT x 1\n",
        "    p = PP.flatten()[:,None] # NT x 1\n",
        "    \n",
        "    ######################################################################\n",
        "    ######################## Noiseles Data ###############################\n",
        "    ######################################################################\n",
        "    # Training Data    \n",
        "    idx = np.random.choice(N*T, N_train, replace=False)\n",
        "    x_train = x[idx,:]\n",
        "    y_train = y[idx,:]\n",
        "    t_train = t[idx,:]\n",
        "    u_train = u[idx,:]\n",
        "    v_train = v[idx,:]\n",
        "\n",
        "    # Training\n",
        "    model = PhysicsInformedNN(x_train, y_train, t_train, u_train, v_train, layers)\n",
        "    model.train(200000)\n",
        "    #model.train(10000)\n",
        "    # you can see reasonable lambda1 and lambda values from iteration 10000\n",
        "    \n",
        "    # Test Data\n",
        "    snap = np.array([100])\n",
        "    x_star = X_star[:,0:1]\n",
        "    y_star = X_star[:,1:2]\n",
        "    t_star = TT[:,snap]\n",
        "    \n",
        "    u_star = U_star[:,0,snap]\n",
        "    v_star = U_star[:,1,snap]\n",
        "    p_star = P_star[:,snap]\n",
        "    \n",
        "    # Prediction\n",
        "    u_pred, v_pred, p_pred = model.predict(x_star, y_star, t_star)\n",
        "    lambda_1_value = model.sess.run(model.lambda_1)\n",
        "    lambda_2_value = model.sess.run(model.lambda_2)\n",
        "    \n",
        "    # Error\n",
        "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
        "    error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
        "    error_p = np.linalg.norm(p_star-p_pred,2)/np.linalg.norm(p_star,2)\n",
        "\n",
        "    error_lambda_1 = np.abs(lambda_1_value - 1.0)*100\n",
        "    error_lambda_2 = np.abs(lambda_2_value - 0.01)/0.01 * 100\n",
        "    \n",
        "    print('Error u: %e' % (error_u))    \n",
        "    print('Error v: %e' % (error_v))    \n",
        "    print('Error p: %e' % (error_p))    \n",
        "    print('Error l1: %.5f%%' % (error_lambda_1))                             \n",
        "    print('Error l2: %.5f%%' % (error_lambda_2))                  \n",
        "    \n",
        "    # Plot Results\n",
        "#    plot_solution(X_star, u_pred, 1)\n",
        "#    plot_solution(X_star, v_pred, 2)\n",
        "#    plot_solution(X_star, p_pred, 3)    \n",
        "#    plot_solution(X_star, p_star, 4)\n",
        "#    plot_solution(X_star, p_star - p_pred, 5)\n",
        "    \n",
        "    # Predict for plotting\n",
        "    lb = X_star.min(0)\n",
        "    ub = X_star.max(0)\n",
        "    nn = 200\n",
        "    x = np.linspace(lb[0], ub[0], nn)\n",
        "    y = np.linspace(lb[1], ub[1], nn)\n",
        "    X, Y = np.meshgrid(x,y)\n",
        "    \n",
        "    UU_star = griddata(X_star, u_pred.flatten(), (X, Y), method='cubic')\n",
        "    VV_star = griddata(X_star, v_pred.flatten(), (X, Y), method='cubic')\n",
        "    PP_star = griddata(X_star, p_pred.flatten(), (X, Y), method='cubic')\n",
        "    P_exact = griddata(X_star, p_star.flatten(), (X, Y), method='cubic')\n",
        "    \n",
        "    \n",
        "    ######################################################################\n",
        "    ########################### Noisy Data ###############################\n",
        "    ######################################################################\n",
        "    noise = 0.01        \n",
        "    u_train = u_train + noise*np.std(u_train)*np.random.randn(u_train.shape[0], u_train.shape[1])\n",
        "    v_train = v_train + noise*np.std(v_train)*np.random.randn(v_train.shape[0], v_train.shape[1])    \n",
        "\n",
        "    # Training\n",
        "    model = PhysicsInformedNN(x_train, y_train, t_train, u_train, v_train, layers)\n",
        "    model.train(10000)\n",
        "    # you can see reasonable lambda1 and lambda values from iteration 10000\n",
        "        \n",
        "    lambda_1_value_noisy = model.sess.run(model.lambda_1)\n",
        "    lambda_2_value_noisy = model.sess.run(model.lambda_2)\n",
        "      \n",
        "    error_lambda_1_noisy = np.abs(lambda_1_value_noisy - 1.0)*100\n",
        "    error_lambda_2_noisy = np.abs(lambda_2_value_noisy - 0.01)/0.01 * 100\n",
        "        \n",
        "    print('Error l1: %.5f%%' % (error_lambda_1_noisy))                             \n",
        "    print('Error l2: %.5f%%' % (error_lambda_2_noisy))     \n",
        "\n",
        "             \n",
        "    \n",
        "    ######################################################################\n",
        "    ############################# Plotting ###############################\n",
        "    ######################################################################    \n",
        "     # Load Data\n",
        "    data_vort = scipy.io.loadmat('/content/drive/MyDrive/Data/cylinder_nektar_t0_vorticity.mat')\n",
        "           \n",
        "    x_vort = data_vort['x'] \n",
        "    y_vort = data_vort['y'] \n",
        "    w_vort = data_vort['w'] \n",
        "    modes = np.asscalar(data_vort['modes'])\n",
        "    nel = np.asscalar(data_vort['nel'])    \n",
        "    \n",
        "    xx_vort = np.reshape(x_vort, (modes+1,modes+1,nel), order = 'F')\n",
        "    yy_vort = np.reshape(y_vort, (modes+1,modes+1,nel), order = 'F')\n",
        "    ww_vort = np.reshape(w_vort, (modes+1,modes+1,nel), order = 'F')\n",
        "    \n",
        "    box_lb = np.array([1.0, -2.0])\n",
        "    box_ub = np.array([8.0, 2.0])\n",
        "    \n",
        "    fig, ax = newfig(1.0, 1.2)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    ####### Row 0: Vorticity ##################    \n",
        "    gs0 = gridspec.GridSpec(1, 2)\n",
        "    gs0.update(top=1-0.06, bottom=1-2/4 + 0.12, left=0.0, right=1.0, wspace=0)\n",
        "    ax = plt.subplot(gs0[:, :])\n",
        "    \n",
        "    for i in range(0, nel):\n",
        "        h = ax.pcolormesh(xx_vort[:,:,i], yy_vort[:,:,i], ww_vort[:,:,i], cmap='seismic',shading='gouraud',  vmin=-3, vmax=3) \n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    \n",
        "    ax.plot([box_lb[0],box_lb[0]],[box_lb[1],box_ub[1]],'k',linewidth = 1)\n",
        "    ax.plot([box_ub[0],box_ub[0]],[box_lb[1],box_ub[1]],'k',linewidth = 1)\n",
        "    ax.plot([box_lb[0],box_ub[0]],[box_lb[1],box_lb[1]],'k',linewidth = 1)\n",
        "    ax.plot([box_lb[0],box_ub[0]],[box_ub[1],box_ub[1]],'k',linewidth = 1)\n",
        "    \n",
        "    ax.set_aspect('equal', 'box')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$y$')\n",
        "    ax.set_title('Vorticity', fontsize = 10)\n",
        "    \n",
        "    \n",
        "    ####### Row 1: Training data ##################\n",
        "    ########      u(t,x,y)     ###################        \n",
        "    gs1 = gridspec.GridSpec(1, 2)\n",
        "    gs1.update(top=1-2/4, bottom=0.0, left=0.01, right=0.99, wspace=0)\n",
        "    ax = plt.subplot(gs1[:, 0],  projection='3d')\n",
        "    ax.axis('off')\n",
        "\n",
        "    r1 = [x_star.min(), x_star.max()]\n",
        "    r2 = [data['t'].min(), data['t'].max()]       \n",
        "    r3 = [y_star.min(), y_star.max()]\n",
        "    \n",
        "    for s, e in combinations(np.array(list(product(r1,r2,r3))), 2):\n",
        "        if np.sum(np.abs(s-e)) == r1[1]-r1[0] or np.sum(np.abs(s-e)) == r2[1]-r2[0] or np.sum(np.abs(s-e)) == r3[1]-r3[0]:\n",
        "            ax.plot3D(*zip(s,e), color=\"k\", linewidth = 0.5)   \n",
        "\n",
        "    ax.scatter(x_train, t_train, y_train, s = 0.1)\n",
        "    ax.contourf(X,UU_star,Y, zdir = 'y', offset = t_star.mean(), cmap='rainbow', alpha = 0.8)\n",
        "              \n",
        "    ax.text(x_star.mean(), data['t'].min() - 1, y_star.min() - 1, '$x$')\n",
        "    ax.text(x_star.max()+1, data['t'].mean(), y_star.min() - 1, '$t$')\n",
        "    ax.text(x_star.min()-1, data['t'].min() - 0.5, y_star.mean(), '$y$')\n",
        "    ax.text(x_star.min()-3, data['t'].mean(), y_star.max() + 1, '$u(t,x,y)$')    \n",
        "    ax.set_xlim3d(r1)\n",
        "    ax.set_ylim3d(r2)\n",
        "    ax.set_zlim3d(r3)\n",
        "    axisEqual3D(ax)\n",
        "    \n",
        "    ########      v(t,x,y)     ###################        \n",
        "    ax = plt.subplot(gs1[:, 1],  projection='3d')\n",
        "    ax.axis('off')\n",
        "    \n",
        "    r1 = [x_star.min(), x_star.max()]\n",
        "    r2 = [data['t'].min(), data['t'].max()]       \n",
        "    r3 = [y_star.min(), y_star.max()]\n",
        "    \n",
        "    for s, e in combinations(np.array(list(product(r1,r2,r3))), 2):\n",
        "        if np.sum(np.abs(s-e)) == r1[1]-r1[0] or np.sum(np.abs(s-e)) == r2[1]-r2[0] or np.sum(np.abs(s-e)) == r3[1]-r3[0]:\n",
        "            ax.plot3D(*zip(s,e), color=\"k\", linewidth = 0.5)   \n",
        "\n",
        "    ax.scatter(x_train, t_train, y_train, s = 0.1)\n",
        "    ax.contourf(X,VV_star,Y, zdir = 'y', offset = t_star.mean(), cmap='rainbow', alpha = 0.8)\n",
        "              \n",
        "    ax.text(x_star.mean(), data['t'].min() - 1, y_star.min() - 1, '$x$')\n",
        "    ax.text(x_star.max()+1, data['t'].mean(), y_star.min() - 1, '$t$')\n",
        "    ax.text(x_star.min()-1, data['t'].min() - 0.5, y_star.mean(), '$y$')\n",
        "    ax.text(x_star.min()-3, data['t'].mean(), y_star.max() + 1, '$v(t,x,y)$')    \n",
        "    ax.set_xlim3d(r1)\n",
        "    ax.set_ylim3d(r2)\n",
        "    ax.set_zlim3d(r3)\n",
        "    axisEqual3D(ax)\n",
        "    \n",
        "    # savefig('./figures/NavierStokes_data') \n",
        "\n",
        "    \n",
        "    fig, ax = newfig(1.015, 0.8)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    ######## Row 2: Pressure #######################\n",
        "    ########      Predicted p(t,x,y)     ########### \n",
        "    gs2 = gridspec.GridSpec(1, 2)\n",
        "    gs2.update(top=1, bottom=1-1/2, left=0.1, right=0.9, wspace=0.5)\n",
        "    ax = plt.subplot(gs2[:, 0])\n",
        "    h = ax.imshow(PP_star, interpolation='nearest', cmap='rainbow', \n",
        "                  extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
        "                  origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$y$')\n",
        "    ax.set_aspect('equal', 'box')\n",
        "    ax.set_title('Predicted pressure', fontsize = 10)\n",
        "    \n",
        "    ########     Exact p(t,x,y)     ########### \n",
        "    ax = plt.subplot(gs2[:, 1])\n",
        "    h = ax.imshow(P_exact, interpolation='nearest', cmap='rainbow', \n",
        "                  extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
        "                  origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$y$')\n",
        "    ax.set_aspect('equal', 'box')\n",
        "    ax.set_title('Exact pressure', fontsize = 10)\n",
        "    \n",
        "    \n",
        "    ######## Row 3: Table #######################\n",
        "    gs3 = gridspec.GridSpec(1, 2)\n",
        "    gs3.update(top=1-1/2, bottom=0.0, left=0.0, right=1.0, wspace=0)\n",
        "    ax = plt.subplot(gs3[:, :])\n",
        "    ax.axis('off')\n",
        "    \n",
        "    s = r'$\\begin{tabular}{|c|c|}';\n",
        "    s = s + r' \\hline'\n",
        "    s = s + r' Correct PDE & $\\begin{array}{c}'\n",
        "    s = s + r' u_t + (u u_x + v u_y) = -p_x + 0.01 (u_{xx} + u_{yy})\\\\'\n",
        "    s = s + r' v_t + (u v_x + v v_y) = -p_y + 0.01 (v_{xx} + v_{yy})'\n",
        "    s = s + r' \\end{array}$ \\\\ '\n",
        "    s = s + r' \\hline'\n",
        "    s = s + r' Identified PDE (clean data) & $\\begin{array}{c}'\n",
        "    s = s + r' u_t + %.3f (u u_x + v u_y) = -p_x + %.5f (u_{xx} + u_{yy})' % (lambda_1_value, lambda_2_value)\n",
        "    s = s + r' \\\\'\n",
        "    s = s + r' v_t + %.3f (u v_x + v v_y) = -p_y + %.5f (v_{xx} + v_{yy})' % (lambda_1_value, lambda_2_value)\n",
        "    s = s + r' \\end{array}$ \\\\ '\n",
        "    s = s + r' \\hline'\n",
        "    s = s + r' Identified PDE (1\\% noise) & $\\begin{array}{c}'\n",
        "    s = s + r' u_t + %.3f (u u_x + v u_y) = -p_x + %.5f (u_{xx} + u_{yy})' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "    s = s + r' \\\\'\n",
        "    s = s + r' v_t + %.3f (u v_x + v v_y) = -p_y + %.5f (v_{xx} + v_{yy})' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "    s = s + r' \\end{array}$ \\\\ '\n",
        "    s = s + r' \\hline'\n",
        "    s = s + r' \\end{tabular}$'\n",
        " \n",
        "    ax.text(0.015,0.0,s)\n",
        "    \n",
        "    # savefig('./figures/NavierStokes_prediction')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7J6GggYQ9_9-",
        "outputId": "a03a503a-8856-42a7-ddbb-0e8b5bdcf148"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It: 0, Loss: 4.186e+02, l1: -0.001, l2: 0.00100, Time: 17.37\n",
            "It: 10, Loss: 2.803e+02, l1: -0.007, l2: 0.00696, Time: 0.57\n",
            "It: 20, Loss: 2.072e+02, l1: 0.002, l2: -0.00210, Time: 0.53\n",
            "It: 30, Loss: 1.784e+02, l1: 0.013, l2: -0.00293, Time: 0.58\n",
            "It: 40, Loss: 1.560e+02, l1: 0.019, l2: -0.01200, Time: 0.53\n",
            "It: 50, Loss: 1.367e+02, l1: 0.014, l2: -0.01668, Time: 0.57\n",
            "It: 60, Loss: 1.237e+02, l1: 0.001, l2: -0.01392, Time: 0.55\n",
            "It: 70, Loss: 1.148e+02, l1: -0.014, l2: -0.00958, Time: 0.94\n",
            "It: 80, Loss: 1.078e+02, l1: -0.028, l2: -0.00565, Time: 0.86\n",
            "It: 90, Loss: 1.020e+02, l1: -0.040, l2: -0.00091, Time: 0.54\n",
            "It: 100, Loss: 9.708e+01, l1: -0.050, l2: 0.00548, Time: 0.51\n",
            "It: 110, Loss: 9.249e+01, l1: -0.059, l2: 0.01287, Time: 0.53\n",
            "It: 120, Loss: 8.806e+01, l1: -0.067, l2: 0.01918, Time: 0.53\n",
            "It: 130, Loss: 8.355e+01, l1: -0.072, l2: 0.02250, Time: 0.56\n",
            "It: 140, Loss: 7.872e+01, l1: -0.073, l2: 0.02135, Time: 0.57\n",
            "It: 150, Loss: 7.355e+01, l1: -0.071, l2: 0.01409, Time: 0.52\n",
            "It: 160, Loss: 6.854e+01, l1: -0.066, l2: 0.00170, Time: 0.53\n",
            "It: 170, Loss: 6.474e+01, l1: -0.061, l2: -0.00856, Time: 0.53\n",
            "It: 180, Loss: 6.248e+01, l1: -0.058, l2: -0.00515, Time: 0.54\n",
            "It: 190, Loss: 6.103e+01, l1: -0.053, l2: 0.00056, Time: 0.52\n",
            "It: 200, Loss: 6.022e+01, l1: -0.046, l2: -0.00365, Time: 0.54\n",
            "It: 210, Loss: 5.891e+01, l1: -0.041, l2: -0.00473, Time: 0.51\n",
            "It: 220, Loss: 5.789e+01, l1: -0.037, l2: -0.00224, Time: 0.52\n",
            "It: 230, Loss: 5.695e+01, l1: -0.030, l2: -0.00195, Time: 0.51\n",
            "It: 240, Loss: 5.613e+01, l1: -0.023, l2: -0.00107, Time: 0.52\n",
            "It: 250, Loss: 5.544e+01, l1: -0.015, l2: -0.00011, Time: 0.51\n",
            "It: 260, Loss: 5.516e+01, l1: -0.006, l2: 0.00025, Time: 0.53\n",
            "It: 270, Loss: 5.429e+01, l1: 0.003, l2: 0.00069, Time: 0.50\n",
            "It: 280, Loss: 5.377e+01, l1: 0.011, l2: 0.00096, Time: 0.54\n",
            "It: 290, Loss: 5.332e+01, l1: 0.018, l2: 0.00117, Time: 0.52\n",
            "It: 300, Loss: 5.303e+01, l1: 0.023, l2: 0.00130, Time: 0.53\n",
            "It: 310, Loss: 5.265e+01, l1: 0.028, l2: 0.00142, Time: 0.52\n",
            "It: 320, Loss: 5.243e+01, l1: 0.032, l2: 0.00144, Time: 0.51\n",
            "It: 330, Loss: 5.188e+01, l1: 0.035, l2: 0.00152, Time: 0.49\n",
            "It: 340, Loss: 5.171e+01, l1: 0.037, l2: 0.00152, Time: 0.52\n",
            "It: 350, Loss: 5.150e+01, l1: 0.039, l2: 0.00151, Time: 0.53\n",
            "It: 360, Loss: 5.166e+01, l1: 0.041, l2: 0.00154, Time: 0.52\n",
            "It: 370, Loss: 5.131e+01, l1: 0.043, l2: 0.00157, Time: 0.52\n",
            "It: 380, Loss: 5.116e+01, l1: 0.045, l2: 0.00167, Time: 0.54\n",
            "It: 390, Loss: 5.108e+01, l1: 0.047, l2: 0.00174, Time: 1.28\n",
            "It: 400, Loss: 5.094e+01, l1: 0.050, l2: 0.00181, Time: 0.52\n",
            "It: 410, Loss: 5.084e+01, l1: 0.052, l2: 0.00187, Time: 0.51\n",
            "It: 420, Loss: 5.075e+01, l1: 0.053, l2: 0.00192, Time: 0.52\n",
            "It: 430, Loss: 5.067e+01, l1: 0.055, l2: 0.00197, Time: 0.49\n",
            "It: 440, Loss: 5.081e+01, l1: 0.056, l2: 0.00199, Time: 0.52\n",
            "It: 450, Loss: 5.093e+01, l1: 0.057, l2: 0.00200, Time: 0.50\n",
            "It: 460, Loss: 5.055e+01, l1: 0.058, l2: 0.00201, Time: 0.52\n",
            "It: 470, Loss: 5.039e+01, l1: 0.058, l2: 0.00198, Time: 0.50\n",
            "It: 480, Loss: 5.032e+01, l1: 0.058, l2: 0.00194, Time: 0.53\n",
            "It: 490, Loss: 5.024e+01, l1: 0.057, l2: 0.00188, Time: 0.51\n",
            "It: 500, Loss: 5.019e+01, l1: 0.056, l2: 0.00181, Time: 0.52\n",
            "It: 510, Loss: 5.105e+01, l1: 0.055, l2: 0.00171, Time: 0.52\n",
            "It: 520, Loss: 5.016e+01, l1: 0.053, l2: 0.00163, Time: 0.50\n",
            "It: 530, Loss: 5.001e+01, l1: 0.051, l2: 0.00151, Time: 0.52\n",
            "It: 540, Loss: 4.998e+01, l1: 0.048, l2: 0.00137, Time: 0.54\n",
            "It: 550, Loss: 4.990e+01, l1: 0.046, l2: 0.00125, Time: 0.49\n",
            "It: 560, Loss: 4.985e+01, l1: 0.044, l2: 0.00111, Time: 0.52\n",
            "It: 570, Loss: 4.986e+01, l1: 0.041, l2: 0.00097, Time: 0.53\n",
            "It: 580, Loss: 5.008e+01, l1: 0.038, l2: 0.00082, Time: 0.50\n",
            "It: 590, Loss: 4.987e+01, l1: 0.035, l2: 0.00068, Time: 0.52\n",
            "It: 600, Loss: 4.967e+01, l1: 0.033, l2: 0.00053, Time: 0.52\n",
            "It: 610, Loss: 4.966e+01, l1: 0.030, l2: 0.00040, Time: 0.51\n",
            "It: 620, Loss: 4.960e+01, l1: 0.028, l2: 0.00027, Time: 0.50\n",
            "It: 630, Loss: 4.954e+01, l1: 0.026, l2: 0.00015, Time: 0.52\n",
            "It: 640, Loss: 4.958e+01, l1: 0.023, l2: 0.00002, Time: 0.50\n",
            "It: 650, Loss: 4.951e+01, l1: 0.021, l2: -0.00018, Time: 0.52\n",
            "It: 660, Loss: 4.944e+01, l1: 0.018, l2: -0.00027, Time: 0.50\n",
            "It: 670, Loss: 4.943e+01, l1: 0.016, l2: -0.00036, Time: 0.51\n",
            "It: 680, Loss: 4.938e+01, l1: 0.014, l2: -0.00045, Time: 0.53\n",
            "It: 690, Loss: 4.933e+01, l1: 0.012, l2: -0.00055, Time: 0.50\n",
            "It: 700, Loss: 4.930e+01, l1: 0.011, l2: -0.00065, Time: 0.50\n",
            "It: 710, Loss: 4.926e+01, l1: 0.009, l2: -0.00074, Time: 0.51\n",
            "It: 720, Loss: 4.923e+01, l1: 0.007, l2: -0.00084, Time: 0.50\n",
            "It: 730, Loss: 4.919e+01, l1: 0.006, l2: -0.00093, Time: 0.52\n",
            "It: 740, Loss: 4.934e+01, l1: 0.004, l2: -0.00103, Time: 0.49\n",
            "It: 750, Loss: 4.918e+01, l1: 0.001, l2: -0.00114, Time: 0.50\n",
            "It: 760, Loss: 4.926e+01, l1: -0.001, l2: -0.00119, Time: 0.51\n",
            "It: 770, Loss: 4.912e+01, l1: -0.002, l2: -0.00131, Time: 0.51\n",
            "It: 780, Loss: 4.904e+01, l1: -0.004, l2: -0.00136, Time: 0.49\n",
            "It: 790, Loss: 4.900e+01, l1: -0.005, l2: -0.00141, Time: 0.50\n",
            "It: 800, Loss: 4.896e+01, l1: -0.006, l2: -0.00147, Time: 0.52\n",
            "It: 810, Loss: 4.892e+01, l1: -0.008, l2: -0.00152, Time: 0.52\n",
            "It: 820, Loss: 4.894e+01, l1: -0.009, l2: -0.00158, Time: 0.50\n",
            "It: 830, Loss: 4.970e+01, l1: -0.011, l2: -0.00164, Time: 0.50\n",
            "It: 840, Loss: 4.911e+01, l1: -0.013, l2: -0.00175, Time: 0.51\n",
            "It: 850, Loss: 4.886e+01, l1: -0.016, l2: -0.00177, Time: 0.53\n",
            "It: 860, Loss: 4.878e+01, l1: -0.017, l2: -0.00187, Time: 0.51\n",
            "It: 870, Loss: 4.872e+01, l1: -0.019, l2: -0.00191, Time: 0.50\n",
            "It: 880, Loss: 4.867e+01, l1: -0.020, l2: -0.00195, Time: 0.49\n",
            "It: 890, Loss: 4.862e+01, l1: -0.021, l2: -0.00199, Time: 0.51\n",
            "It: 900, Loss: 4.858e+01, l1: -0.023, l2: -0.00204, Time: 0.49\n",
            "It: 910, Loss: 4.854e+01, l1: -0.025, l2: -0.00210, Time: 0.50\n",
            "It: 920, Loss: 4.947e+01, l1: -0.028, l2: -0.00194, Time: 0.50\n",
            "It: 930, Loss: 4.883e+01, l1: -0.031, l2: -0.00236, Time: 0.54\n",
            "It: 940, Loss: 4.846e+01, l1: -0.035, l2: -0.00230, Time: 0.50\n",
            "It: 950, Loss: 4.843e+01, l1: -0.037, l2: -0.00252, Time: 0.50\n",
            "It: 960, Loss: 4.835e+01, l1: -0.039, l2: -0.00249, Time: 0.51\n",
            "It: 970, Loss: 4.830e+01, l1: -0.041, l2: -0.00255, Time: 0.51\n",
            "It: 980, Loss: 4.828e+01, l1: -0.044, l2: -0.00261, Time: 0.49\n",
            "It: 990, Loss: 4.988e+01, l1: -0.047, l2: -0.00259, Time: 0.50\n",
            "It: 1000, Loss: 4.829e+01, l1: -0.049, l2: -0.00267, Time: 0.51\n",
            "It: 1010, Loss: 4.822e+01, l1: -0.053, l2: -0.00289, Time: 0.52\n",
            "It: 1020, Loss: 4.814e+01, l1: -0.058, l2: -0.00295, Time: 0.52\n",
            "It: 1030, Loss: 4.808e+01, l1: -0.062, l2: -0.00311, Time: 0.50\n",
            "It: 1040, Loss: 4.802e+01, l1: -0.065, l2: -0.00314, Time: 0.53\n",
            "It: 1050, Loss: 4.799e+01, l1: -0.068, l2: -0.00324, Time: 0.53\n",
            "It: 1060, Loss: 4.865e+01, l1: -0.072, l2: -0.00314, Time: 0.49\n",
            "It: 1070, Loss: 4.799e+01, l1: -0.077, l2: -0.00355, Time: 0.51\n",
            "It: 1080, Loss: 4.788e+01, l1: -0.080, l2: -0.00349, Time: 0.50\n",
            "It: 1090, Loss: 4.785e+01, l1: -0.082, l2: -0.00363, Time: 0.53\n",
            "It: 1100, Loss: 4.800e+01, l1: -0.085, l2: -0.00366, Time: 0.48\n",
            "It: 1110, Loss: 4.793e+01, l1: -0.087, l2: -0.00370, Time: 0.50\n",
            "It: 1120, Loss: 4.794e+01, l1: -0.089, l2: -0.00376, Time: 0.50\n",
            "It: 1130, Loss: 4.778e+01, l1: -0.094, l2: -0.00390, Time: 0.55\n",
            "It: 1140, Loss: 4.774e+01, l1: -0.097, l2: -0.00399, Time: 0.52\n",
            "It: 1150, Loss: 4.768e+01, l1: -0.099, l2: -0.00397, Time: 0.53\n",
            "It: 1160, Loss: 4.764e+01, l1: -0.101, l2: -0.00400, Time: 0.51\n",
            "It: 1170, Loss: 4.762e+01, l1: -0.103, l2: -0.00400, Time: 0.53\n",
            "It: 1180, Loss: 4.830e+01, l1: -0.105, l2: -0.00396, Time: 0.50\n",
            "It: 1190, Loss: 4.766e+01, l1: -0.108, l2: -0.00379, Time: 0.51\n",
            "It: 1200, Loss: 4.763e+01, l1: -0.109, l2: -0.00426, Time: 0.50\n",
            "It: 1210, Loss: 4.758e+01, l1: -0.109, l2: -0.00406, Time: 0.51\n",
            "It: 1220, Loss: 4.751e+01, l1: -0.110, l2: -0.00412, Time: 0.49\n",
            "It: 1230, Loss: 4.749e+01, l1: -0.110, l2: -0.00406, Time: 0.50\n",
            "It: 1240, Loss: 4.855e+01, l1: -0.111, l2: -0.00389, Time: 0.51\n",
            "It: 1250, Loss: 4.825e+01, l1: -0.109, l2: -0.00392, Time: 0.52\n",
            "It: 1260, Loss: 4.763e+01, l1: -0.111, l2: -0.00404, Time: 0.51\n",
            "It: 1270, Loss: 4.743e+01, l1: -0.115, l2: -0.00414, Time: 0.53\n",
            "It: 1280, Loss: 4.738e+01, l1: -0.116, l2: -0.00401, Time: 0.50\n",
            "It: 1290, Loss: 4.736e+01, l1: -0.115, l2: -0.00403, Time: 0.52\n",
            "It: 1300, Loss: 4.733e+01, l1: -0.114, l2: -0.00393, Time: 0.50\n",
            "It: 1310, Loss: 4.731e+01, l1: -0.115, l2: -0.00389, Time: 0.50\n",
            "It: 1320, Loss: 4.728e+01, l1: -0.115, l2: -0.00383, Time: 0.49\n",
            "It: 1330, Loss: 4.726e+01, l1: -0.115, l2: -0.00378, Time: 0.54\n",
            "It: 1340, Loss: 4.724e+01, l1: -0.115, l2: -0.00374, Time: 0.50\n",
            "It: 1350, Loss: 4.729e+01, l1: -0.115, l2: -0.00369, Time: 0.52\n",
            "It: 1360, Loss: 4.788e+01, l1: -0.116, l2: -0.00388, Time: 0.50\n",
            "It: 1370, Loss: 4.732e+01, l1: -0.115, l2: -0.00356, Time: 0.55\n",
            "It: 1380, Loss: 4.725e+01, l1: -0.115, l2: -0.00365, Time: 0.51\n",
            "It: 1390, Loss: 4.717e+01, l1: -0.114, l2: -0.00366, Time: 0.49\n",
            "It: 1400, Loss: 4.712e+01, l1: -0.114, l2: -0.00349, Time: 0.50\n",
            "It: 1410, Loss: 4.709e+01, l1: -0.113, l2: -0.00347, Time: 0.51\n",
            "It: 1420, Loss: 4.707e+01, l1: -0.113, l2: -0.00337, Time: 0.51\n",
            "It: 1430, Loss: 4.773e+01, l1: -0.112, l2: -0.00321, Time: 0.49\n",
            "It: 1440, Loss: 4.809e+01, l1: -0.109, l2: -0.00336, Time: 0.50\n",
            "It: 1450, Loss: 4.726e+01, l1: -0.110, l2: -0.00307, Time: 0.50\n",
            "It: 1460, Loss: 4.698e+01, l1: -0.114, l2: -0.00331, Time: 0.50\n",
            "It: 1470, Loss: 4.697e+01, l1: -0.113, l2: -0.00314, Time: 0.49\n",
            "It: 1480, Loss: 4.694e+01, l1: -0.111, l2: -0.00306, Time: 0.51\n",
            "It: 1490, Loss: 4.691e+01, l1: -0.111, l2: -0.00301, Time: 0.49\n",
            "It: 1500, Loss: 4.688e+01, l1: -0.111, l2: -0.00292, Time: 0.51\n",
            "It: 1510, Loss: 4.686e+01, l1: -0.111, l2: -0.00287, Time: 0.49\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d46334b7cd9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhysicsInformedNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;31m#model.train(10000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# you can see reasonable lambda1 and lambda values from iteration 10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-d46334b7cd9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, nIter)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op_Adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;31m# Print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WM0JxSxb_WV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}