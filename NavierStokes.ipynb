{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2KN6z/JzCCp/ixvQI1aM4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amiralizadeh1/PINNs/blob/master/NavierStokes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFF91tdQWgw9",
        "outputId": "f39af536-6942-47cd-ff75-c99f1008c672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.9.2\n",
            "Uninstalling tensorflow-2.9.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.9.2.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "\n",
            "  Successfully uninstalled tensorflow-2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "id": "swWoyQrjXxul",
        "outputId": "5bca8263-a0d5-4973-bbd3-291030e98d0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 51 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 37.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.50.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.3.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (2.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "edUe1ChVYs7f",
        "outputId": "e752d127-3c81-4ee8-eafb-ea2080ff8238"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-fcda07dc3388>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print tensorflow as tf\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(tensorflow as tf)?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp0daTr7ZDx5",
        "outputId": "8679f692-15ae-4ef8-d812-e709555847c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.50.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (2.0.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-rX9ZUZZMUv",
        "outputId": "1fde114d-972b-4739-fa6a-bcb6b079059c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/Utilities') #upload utilities folder to your google drive before running the lines\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "import time\n",
        "from itertools import product, combinations\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "from plotting import newfig, savefig\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "class PhysicsInformedNN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, x, y, t, u, v, layers):\n",
        "        \n",
        "        X = np.concatenate([x, y, t], 1)\n",
        "        \n",
        "        self.lb = X.min(0)\n",
        "        self.ub = X.max(0)\n",
        "                \n",
        "        self.X = X\n",
        "        \n",
        "        self.x = X[:,0:1]\n",
        "        self.y = X[:,1:2]\n",
        "        self.t = X[:,2:3]\n",
        "        \n",
        "        self.u = u\n",
        "        self.v = v\n",
        "        \n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NN\n",
        "        self.weights, self.biases = self.initialize_NN(layers)        \n",
        "        \n",
        "        # Initialize parameters\n",
        "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
        "        self.lambda_2 = tf.Variable([0.0], dtype=tf.float32)\n",
        "        \n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
        "        self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]])\n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
        "        \n",
        "        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
        "        self.v_tf = tf.placeholder(tf.float32, shape=[None, self.v.shape[1]])\n",
        "        \n",
        "        self.u_pred, self.v_pred, self.p_pred, self.f_u_pred, self.f_v_pred = self.net_NS(self.x_tf, self.y_tf, self.t_tf)\n",
        "        \n",
        "        self.loss = tf.reduce_sum(tf.square(self.u_tf - self.u_pred)) + \\\n",
        "                    tf.reduce_sum(tf.square(self.v_tf - self.v_pred)) + \\\n",
        "                    tf.reduce_sum(tf.square(self.f_u_pred)) + \\\n",
        "                    tf.reduce_sum(tf.square(self.f_v_pred))\n",
        "                    \n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 50000,\n",
        "                                                                           'maxfun': 50000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
        "        # learn more about the options: docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html\n",
        "        \n",
        "        \n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)        \n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]        \n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "    \n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "        \n",
        "    def net_NS(self, x, y, t):\n",
        "        lambda_1 = self.lambda_1\n",
        "        lambda_2 = self.lambda_2\n",
        "        \n",
        "        psi_and_p = self.neural_net(tf.concat([x,y,t], 1), self.weights, self.biases)\n",
        "        psi = psi_and_p[:,0:1]\n",
        "        p = psi_and_p[:,1:2]\n",
        "        \n",
        "        u = tf.gradients(psi, y)[0]\n",
        "        v = -tf.gradients(psi, x)[0]  \n",
        "        \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_y = tf.gradients(u, y)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        u_yy = tf.gradients(u_y, y)[0]\n",
        "        \n",
        "        v_t = tf.gradients(v, t)[0]\n",
        "        v_x = tf.gradients(v, x)[0]\n",
        "        v_y = tf.gradients(v, y)[0]\n",
        "        v_xx = tf.gradients(v_x, x)[0]\n",
        "        v_yy = tf.gradients(v_y, y)[0]\n",
        "        \n",
        "        p_x = tf.gradients(p, x)[0]\n",
        "        p_y = tf.gradients(p, y)[0]\n",
        "\n",
        "        f_u = u_t + lambda_1*(u*u_x + v*u_y) + p_x - lambda_2*(u_xx + u_yy) \n",
        "        f_v = v_t + lambda_1*(u*v_x + v*v_y) + p_y - lambda_2*(v_xx + v_yy)\n",
        "        \n",
        "        return u, v, p, f_u, f_v\n",
        "    \n",
        "    def callback(self, loss, lambda_1, lambda_2):\n",
        "        print('Loss: %.3e, l1: %.3f, l2: %.5f' % (loss, lambda_1, lambda_2))\n",
        "      \n",
        "    def train(self, nIter): \n",
        "\n",
        "        tf_dict = {self.x_tf: self.x, self.y_tf: self.y, self.t_tf: self.t,\n",
        "                   self.u_tf: self.u, self.v_tf: self.v}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(nIter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                lambda_1_value = self.sess.run(self.lambda_1)\n",
        "                lambda_2_value = self.sess.run(self.lambda_2)\n",
        "                print('It: %d, Loss: %.3e, l1: %.3f, l2: %.5f, Time: %.2f' % \n",
        "                      (it, loss_value, lambda_1_value, lambda_2_value, elapsed))\n",
        "                start_time = time.time()\n",
        "            \n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict = tf_dict,\n",
        "                                fetches = [self.loss, self.lambda_1, self.lambda_2],\n",
        "                                loss_callback = self.callback)\n",
        "            \n",
        "    \n",
        "    def predict(self, x_star, y_star, t_star):\n",
        "        \n",
        "        tf_dict = {self.x_tf: x_star, self.y_tf: y_star, self.t_tf: t_star}\n",
        "        \n",
        "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
        "        v_star = self.sess.run(self.v_pred, tf_dict)\n",
        "        p_star = self.sess.run(self.p_pred, tf_dict)\n",
        "        \n",
        "        return u_star, v_star, p_star\n",
        "\n",
        "def plot_solution(X_star, u_star, index):\n",
        "    \n",
        "    lb = X_star.min(0)\n",
        "    ub = X_star.max(0)\n",
        "    nn = 200\n",
        "    x = np.linspace(lb[0], ub[0], nn)\n",
        "    y = np.linspace(lb[1], ub[1], nn)\n",
        "    X, Y = np.meshgrid(x,y)\n",
        "    \n",
        "    U_star = griddata(X_star, u_star.flatten(), (X, Y), method='cubic')\n",
        "    \n",
        "    plt.figure(index)\n",
        "    plt.pcolor(X,Y,U_star, cmap = 'jet')\n",
        "    plt.colorbar()\n",
        "    \n",
        "    \n",
        "def axisEqual3D(ax):\n",
        "    extents = np.array([getattr(ax, 'get_{}lim'.format(dim))() for dim in 'xyz'])\n",
        "    sz = extents[:,1] - extents[:,0]\n",
        "    centers = np.mean(extents, axis=1)\n",
        "    maxsize = max(abs(sz))\n",
        "    r = maxsize/4\n",
        "    for ctr, dim in zip(centers, 'xyz'):\n",
        "        getattr(ax, 'set_{}lim'.format(dim))(ctr - r, ctr + r)\n",
        "        \n",
        "        \n",
        "if __name__ == \"__main__\": \n",
        "      \n",
        "    N_train = 5000\n",
        "    \n",
        "    layers = [3, 20, 20, 20, 20, 20, 20, 20, 20, 2]\n",
        "\n",
        "    # Load Data\n",
        "    data = scipy.io.loadmat('/content/drive/MyDrive/Data/cylinder_nektar_wake.mat')\n",
        "           \n",
        "    U_star = data['U_star'] # N x 2 x T\n",
        "    P_star = data['p_star'] # N x T\n",
        "    t_star = data['t'] # T x 1\n",
        "    X_star = data['X_star'] # N x 2\n",
        "    \n",
        "    N = X_star.shape[0]\n",
        "    T = t_star.shape[0]\n",
        "    \n",
        "    # Rearrange Data \n",
        "    XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
        "    YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
        "    TT = np.tile(t_star, (1,N)).T # N x T\n",
        "    \n",
        "    UU = U_star[:,0,:] # N x T\n",
        "    VV = U_star[:,1,:] # N x T\n",
        "    PP = P_star # N x T\n",
        "    \n",
        "    x = XX.flatten()[:,None] # NT x 1\n",
        "    y = YY.flatten()[:,None] # NT x 1\n",
        "    t = TT.flatten()[:,None] # NT x 1\n",
        "    \n",
        "    u = UU.flatten()[:,None] # NT x 1\n",
        "    v = VV.flatten()[:,None] # NT x 1\n",
        "    p = PP.flatten()[:,None] # NT x 1\n",
        "    \n",
        "    ######################################################################\n",
        "    ######################## Noiseles Data ###############################\n",
        "    ######################################################################\n",
        "    # Training Data    \n",
        "    idx = np.random.choice(N*T, N_train, replace=False)\n",
        "    x_train = x[idx,:]\n",
        "    y_train = y[idx,:]\n",
        "    t_train = t[idx,:]\n",
        "    u_train = u[idx,:]\n",
        "    v_train = v[idx,:]\n",
        "\n",
        "    # Training\n",
        "    model = PhysicsInformedNN(x_train, y_train, t_train, u_train, v_train, layers)\n",
        "    model.train(10000)\n",
        "    # you can see reasonable lambda1 and lambda values from iteration 10000\n",
        "    \n",
        "    # Test Data\n",
        "    snap = np.array([100])\n",
        "    x_star = X_star[:,0:1]\n",
        "    y_star = X_star[:,1:2]\n",
        "    t_star = TT[:,snap]\n",
        "    \n",
        "    u_star = U_star[:,0,snap]\n",
        "    v_star = U_star[:,1,snap]\n",
        "    p_star = P_star[:,snap]\n",
        "    \n",
        "    # Prediction\n",
        "    u_pred, v_pred, p_pred = model.predict(x_star, y_star, t_star)\n",
        "    lambda_1_value = model.sess.run(model.lambda_1)\n",
        "    lambda_2_value = model.sess.run(model.lambda_2)\n",
        "    \n",
        "    # Error\n",
        "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
        "    error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
        "    error_p = np.linalg.norm(p_star-p_pred,2)/np.linalg.norm(p_star,2)\n",
        "\n",
        "    error_lambda_1 = np.abs(lambda_1_value - 1.0)*100\n",
        "    error_lambda_2 = np.abs(lambda_2_value - 0.01)/0.01 * 100\n",
        "    \n",
        "    print('Error u: %e' % (error_u))    \n",
        "    print('Error v: %e' % (error_v))    \n",
        "    print('Error p: %e' % (error_p))    \n",
        "    print('Error l1: %.5f%%' % (error_lambda_1))                             \n",
        "    print('Error l2: %.5f%%' % (error_lambda_2))                  \n",
        "    \n",
        "    # Plot Results\n",
        "#    plot_solution(X_star, u_pred, 1)\n",
        "#    plot_solution(X_star, v_pred, 2)\n",
        "#    plot_solution(X_star, p_pred, 3)    \n",
        "#    plot_solution(X_star, p_star, 4)\n",
        "#    plot_solution(X_star, p_star - p_pred, 5)\n",
        "    \n",
        "    # Predict for plotting\n",
        "    lb = X_star.min(0)\n",
        "    ub = X_star.max(0)\n",
        "    nn = 200\n",
        "    x = np.linspace(lb[0], ub[0], nn)\n",
        "    y = np.linspace(lb[1], ub[1], nn)\n",
        "    X, Y = np.meshgrid(x,y)\n",
        "    \n",
        "    UU_star = griddata(X_star, u_pred.flatten(), (X, Y), method='cubic')\n",
        "    VV_star = griddata(X_star, v_pred.flatten(), (X, Y), method='cubic')\n",
        "    PP_star = griddata(X_star, p_pred.flatten(), (X, Y), method='cubic')\n",
        "    P_exact = griddata(X_star, p_star.flatten(), (X, Y), method='cubic')\n",
        "    \n",
        "    \n",
        "    ######################################################################\n",
        "    ########################### Noisy Data ###############################\n",
        "    ######################################################################\n",
        "    noise = 0.01        \n",
        "    u_train = u_train + noise*np.std(u_train)*np.random.randn(u_train.shape[0], u_train.shape[1])\n",
        "    v_train = v_train + noise*np.std(v_train)*np.random.randn(v_train.shape[0], v_train.shape[1])    \n",
        "\n",
        "    # Training\n",
        "    model = PhysicsInformedNN(x_train, y_train, t_train, u_train, v_train, layers)\n",
        "    model.train(10000)\n",
        "    # you can see reasonable lambda1 and lambda values from iteration 10000\n",
        "        \n",
        "    lambda_1_value_noisy = model.sess.run(model.lambda_1)\n",
        "    lambda_2_value_noisy = model.sess.run(model.lambda_2)\n",
        "      \n",
        "    error_lambda_1_noisy = np.abs(lambda_1_value_noisy - 1.0)*100\n",
        "    error_lambda_2_noisy = np.abs(lambda_2_value_noisy - 0.01)/0.01 * 100\n",
        "        \n",
        "    print('Error l1: %.5f%%' % (error_lambda_1_noisy))                             \n",
        "    print('Error l2: %.5f%%' % (error_lambda_2_noisy))     \n",
        "\n",
        "             \n",
        "    \n",
        "    ######################################################################\n",
        "    ############################# Plotting ###############################\n",
        "    ######################################################################    \n",
        "     # Load Data\n",
        "    data_vort = scipy.io.loadmat('/content/drive/MyDrive/Data/cylinder_nektar_t0_vorticity.mat')\n",
        "           \n",
        "    x_vort = data_vort['x'] \n",
        "    y_vort = data_vort['y'] \n",
        "    w_vort = data_vort['w'] \n",
        "    modes = np.asscalar(data_vort['modes'])\n",
        "    nel = np.asscalar(data_vort['nel'])    \n",
        "    \n",
        "    xx_vort = np.reshape(x_vort, (modes+1,modes+1,nel), order = 'F')\n",
        "    yy_vort = np.reshape(y_vort, (modes+1,modes+1,nel), order = 'F')\n",
        "    ww_vort = np.reshape(w_vort, (modes+1,modes+1,nel), order = 'F')\n",
        "    \n",
        "    box_lb = np.array([1.0, -2.0])\n",
        "    box_ub = np.array([8.0, 2.0])\n",
        "    \n",
        "    fig, ax = newfig(1.0, 1.2)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    ####### Row 0: Vorticity ##################    \n",
        "    gs0 = gridspec.GridSpec(1, 2)\n",
        "    gs0.update(top=1-0.06, bottom=1-2/4 + 0.12, left=0.0, right=1.0, wspace=0)\n",
        "    ax = plt.subplot(gs0[:, :])\n",
        "    \n",
        "    for i in range(0, nel):\n",
        "        h = ax.pcolormesh(xx_vort[:,:,i], yy_vort[:,:,i], ww_vort[:,:,i], cmap='seismic',shading='gouraud',  vmin=-3, vmax=3) \n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    \n",
        "    ax.plot([box_lb[0],box_lb[0]],[box_lb[1],box_ub[1]],'k',linewidth = 1)\n",
        "    ax.plot([box_ub[0],box_ub[0]],[box_lb[1],box_ub[1]],'k',linewidth = 1)\n",
        "    ax.plot([box_lb[0],box_ub[0]],[box_lb[1],box_lb[1]],'k',linewidth = 1)\n",
        "    ax.plot([box_lb[0],box_ub[0]],[box_ub[1],box_ub[1]],'k',linewidth = 1)\n",
        "    \n",
        "    ax.set_aspect('equal', 'box')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$y$')\n",
        "    ax.set_title('Vorticity', fontsize = 10)\n",
        "    \n",
        "    \n",
        "    ####### Row 1: Training data ##################\n",
        "    ########      u(t,x,y)     ###################        \n",
        "    gs1 = gridspec.GridSpec(1, 2)\n",
        "    gs1.update(top=1-2/4, bottom=0.0, left=0.01, right=0.99, wspace=0)\n",
        "    ax = plt.subplot(gs1[:, 0],  projection='3d')\n",
        "    ax.axis('off')\n",
        "\n",
        "    r1 = [x_star.min(), x_star.max()]\n",
        "    r2 = [data['t'].min(), data['t'].max()]       \n",
        "    r3 = [y_star.min(), y_star.max()]\n",
        "    \n",
        "    for s, e in combinations(np.array(list(product(r1,r2,r3))), 2):\n",
        "        if np.sum(np.abs(s-e)) == r1[1]-r1[0] or np.sum(np.abs(s-e)) == r2[1]-r2[0] or np.sum(np.abs(s-e)) == r3[1]-r3[0]:\n",
        "            ax.plot3D(*zip(s,e), color=\"k\", linewidth = 0.5)   \n",
        "\n",
        "    ax.scatter(x_train, t_train, y_train, s = 0.1)\n",
        "    ax.contourf(X,UU_star,Y, zdir = 'y', offset = t_star.mean(), cmap='rainbow', alpha = 0.8)\n",
        "              \n",
        "    ax.text(x_star.mean(), data['t'].min() - 1, y_star.min() - 1, '$x$')\n",
        "    ax.text(x_star.max()+1, data['t'].mean(), y_star.min() - 1, '$t$')\n",
        "    ax.text(x_star.min()-1, data['t'].min() - 0.5, y_star.mean(), '$y$')\n",
        "    ax.text(x_star.min()-3, data['t'].mean(), y_star.max() + 1, '$u(t,x,y)$')    \n",
        "    ax.set_xlim3d(r1)\n",
        "    ax.set_ylim3d(r2)\n",
        "    ax.set_zlim3d(r3)\n",
        "    axisEqual3D(ax)\n",
        "    \n",
        "    ########      v(t,x,y)     ###################        \n",
        "    ax = plt.subplot(gs1[:, 1],  projection='3d')\n",
        "    ax.axis('off')\n",
        "    \n",
        "    r1 = [x_star.min(), x_star.max()]\n",
        "    r2 = [data['t'].min(), data['t'].max()]       \n",
        "    r3 = [y_star.min(), y_star.max()]\n",
        "    \n",
        "    for s, e in combinations(np.array(list(product(r1,r2,r3))), 2):\n",
        "        if np.sum(np.abs(s-e)) == r1[1]-r1[0] or np.sum(np.abs(s-e)) == r2[1]-r2[0] or np.sum(np.abs(s-e)) == r3[1]-r3[0]:\n",
        "            ax.plot3D(*zip(s,e), color=\"k\", linewidth = 0.5)   \n",
        "\n",
        "    ax.scatter(x_train, t_train, y_train, s = 0.1)\n",
        "    ax.contourf(X,VV_star,Y, zdir = 'y', offset = t_star.mean(), cmap='rainbow', alpha = 0.8)\n",
        "              \n",
        "    ax.text(x_star.mean(), data['t'].min() - 1, y_star.min() - 1, '$x$')\n",
        "    ax.text(x_star.max()+1, data['t'].mean(), y_star.min() - 1, '$t$')\n",
        "    ax.text(x_star.min()-1, data['t'].min() - 0.5, y_star.mean(), '$y$')\n",
        "    ax.text(x_star.min()-3, data['t'].mean(), y_star.max() + 1, '$v(t,x,y)$')    \n",
        "    ax.set_xlim3d(r1)\n",
        "    ax.set_ylim3d(r2)\n",
        "    ax.set_zlim3d(r3)\n",
        "    axisEqual3D(ax)\n",
        "    \n",
        "    # savefig('./figures/NavierStokes_data') \n",
        "\n",
        "    \n",
        "    fig, ax = newfig(1.015, 0.8)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    ######## Row 2: Pressure #######################\n",
        "    ########      Predicted p(t,x,y)     ########### \n",
        "    gs2 = gridspec.GridSpec(1, 2)\n",
        "    gs2.update(top=1, bottom=1-1/2, left=0.1, right=0.9, wspace=0.5)\n",
        "    ax = plt.subplot(gs2[:, 0])\n",
        "    h = ax.imshow(PP_star, interpolation='nearest', cmap='rainbow', \n",
        "                  extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
        "                  origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$y$')\n",
        "    ax.set_aspect('equal', 'box')\n",
        "    ax.set_title('Predicted pressure', fontsize = 10)\n",
        "    \n",
        "    ########     Exact p(t,x,y)     ########### \n",
        "    ax = plt.subplot(gs2[:, 1])\n",
        "    h = ax.imshow(P_exact, interpolation='nearest', cmap='rainbow', \n",
        "                  extent=[x_star.min(), x_star.max(), y_star.min(), y_star.max()], \n",
        "                  origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$y$')\n",
        "    ax.set_aspect('equal', 'box')\n",
        "    ax.set_title('Exact pressure', fontsize = 10)\n",
        "    \n",
        "    \n",
        "    ######## Row 3: Table #######################\n",
        "    gs3 = gridspec.GridSpec(1, 2)\n",
        "    gs3.update(top=1-1/2, bottom=0.0, left=0.0, right=1.0, wspace=0)\n",
        "    ax = plt.subplot(gs3[:, :])\n",
        "    ax.axis('off')\n",
        "    \n",
        "    s = r'$\\begin{tabular}{|c|c|}';\n",
        "    s = s + r' \\hline'\n",
        "    s = s + r' Correct PDE & $\\begin{array}{c}'\n",
        "    s = s + r' u_t + (u u_x + v u_y) = -p_x + 0.01 (u_{xx} + u_{yy})\\\\'\n",
        "    s = s + r' v_t + (u v_x + v v_y) = -p_y + 0.01 (v_{xx} + v_{yy})'\n",
        "    s = s + r' \\end{array}$ \\\\ '\n",
        "    s = s + r' \\hline'\n",
        "    s = s + r' Identified PDE (clean data) & $\\begin{array}{c}'\n",
        "    s = s + r' u_t + %.3f (u u_x + v u_y) = -p_x + %.5f (u_{xx} + u_{yy})' % (lambda_1_value, lambda_2_value)\n",
        "    s = s + r' \\\\'\n",
        "    s = s + r' v_t + %.3f (u v_x + v v_y) = -p_y + %.5f (v_{xx} + v_{yy})' % (lambda_1_value, lambda_2_value)\n",
        "    s = s + r' \\end{array}$ \\\\ '\n",
        "    s = s + r' \\hline'\n",
        "    s = s + r' Identified PDE (1\\% noise) & $\\begin{array}{c}'\n",
        "    s = s + r' u_t + %.3f (u u_x + v u_y) = -p_x + %.5f (u_{xx} + u_{yy})' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "    s = s + r' \\\\'\n",
        "    s = s + r' v_t + %.3f (u v_x + v v_y) = -p_y + %.5f (v_{xx} + v_{yy})' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "    s = s + r' \\end{array}$ \\\\ '\n",
        "    s = s + r' \\hline'\n",
        "    s = s + r' \\end{tabular}$'\n",
        " \n",
        "    ax.text(0.015,0.0,s)\n",
        "    \n",
        "    # savefig('./figures/NavierStokes_prediction') \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8vvmr2CZeSg",
        "outputId": "36c6ba8b-ebe9-4a44-b81d-6a80ae22f6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It: 0, Loss: 4.252e+03, l1: -0.001, l2: 0.00100, Time: 16.23\n",
            "It: 10, Loss: 2.863e+03, l1: -0.007, l2: 0.00783, Time: 4.36\n",
            "It: 20, Loss: 2.081e+03, l1: 0.002, l2: -0.00093, Time: 6.66\n",
            "It: 30, Loss: 1.787e+03, l1: 0.013, l2: -0.00408, Time: 4.24\n",
            "It: 40, Loss: 1.565e+03, l1: 0.020, l2: -0.01385, Time: 4.30\n",
            "It: 50, Loss: 1.385e+03, l1: 0.017, l2: -0.01702, Time: 4.34\n",
            "It: 60, Loss: 1.252e+03, l1: 0.007, l2: -0.01472, Time: 4.27\n",
            "It: 70, Loss: 1.151e+03, l1: -0.006, l2: -0.01206, Time: 4.28\n",
            "It: 80, Loss: 1.072e+03, l1: -0.017, l2: -0.00787, Time: 6.42\n",
            "It: 90, Loss: 1.006e+03, l1: -0.023, l2: -0.00074, Time: 4.36\n",
            "It: 100, Loss: 9.503e+02, l1: -0.026, l2: 0.00844, Time: 4.36\n",
            "It: 110, Loss: 8.980e+02, l1: -0.028, l2: 0.01737, Time: 4.37\n",
            "It: 120, Loss: 8.457e+02, l1: -0.028, l2: 0.02313, Time: 4.37\n",
            "It: 130, Loss: 7.903e+02, l1: -0.028, l2: 0.02338, Time: 4.37\n",
            "It: 140, Loss: 7.276e+02, l1: -0.025, l2: 0.01738, Time: 4.32\n",
            "It: 150, Loss: 6.618e+02, l1: -0.018, l2: 0.00608, Time: 4.30\n",
            "It: 160, Loss: 6.207e+02, l1: -0.011, l2: -0.00482, Time: 4.25\n",
            "It: 170, Loss: 6.192e+02, l1: -0.008, l2: -0.00442, Time: 4.29\n",
            "It: 180, Loss: 6.101e+02, l1: -0.005, l2: -0.00112, Time: 4.34\n",
            "It: 190, Loss: 6.054e+02, l1: -0.002, l2: -0.00267, Time: 4.33\n",
            "It: 200, Loss: 5.996e+02, l1: 0.002, l2: -0.00299, Time: 4.35\n",
            "It: 210, Loss: 5.933e+02, l1: 0.006, l2: -0.00105, Time: 4.35\n",
            "It: 220, Loss: 5.859e+02, l1: 0.010, l2: -0.00022, Time: 4.31\n",
            "It: 230, Loss: 5.769e+02, l1: 0.015, l2: 0.00061, Time: 4.28\n",
            "It: 240, Loss: 5.663e+02, l1: 0.020, l2: 0.00122, Time: 4.29\n",
            "It: 250, Loss: 5.569e+02, l1: 0.025, l2: 0.00123, Time: 4.32\n",
            "It: 260, Loss: 5.510e+02, l1: 0.027, l2: 0.00091, Time: 4.32\n",
            "It: 270, Loss: 5.459e+02, l1: 0.026, l2: 0.00061, Time: 4.31\n",
            "It: 280, Loss: 5.406e+02, l1: 0.023, l2: 0.00027, Time: 4.29\n",
            "It: 290, Loss: 5.349e+02, l1: 0.017, l2: -0.00003, Time: 4.30\n",
            "It: 300, Loss: 5.285e+02, l1: 0.012, l2: -0.00021, Time: 4.34\n",
            "It: 310, Loss: 5.216e+02, l1: 0.008, l2: -0.00029, Time: 4.32\n",
            "It: 320, Loss: 5.145e+02, l1: 0.005, l2: -0.00029, Time: 4.27\n",
            "It: 330, Loss: 5.076e+02, l1: 0.003, l2: -0.00024, Time: 4.29\n",
            "It: 340, Loss: 5.013e+02, l1: 0.002, l2: -0.00020, Time: 4.26\n",
            "It: 350, Loss: 4.989e+02, l1: 0.001, l2: -0.00014, Time: 6.32\n",
            "It: 360, Loss: 4.999e+02, l1: 0.002, l2: -0.00010, Time: 6.36\n",
            "It: 370, Loss: 4.903e+02, l1: 0.006, l2: 0.00015, Time: 4.31\n",
            "It: 380, Loss: 4.892e+02, l1: 0.011, l2: 0.00030, Time: 4.42\n",
            "It: 390, Loss: 4.864e+02, l1: 0.014, l2: 0.00041, Time: 4.28\n",
            "It: 400, Loss: 4.844e+02, l1: 0.015, l2: 0.00041, Time: 4.38\n",
            "It: 410, Loss: 4.828e+02, l1: 0.014, l2: 0.00033, Time: 4.40\n",
            "It: 420, Loss: 4.814e+02, l1: 0.011, l2: 0.00018, Time: 4.34\n",
            "It: 430, Loss: 4.803e+02, l1: 0.008, l2: 0.00002, Time: 4.31\n",
            "It: 440, Loss: 4.793e+02, l1: 0.004, l2: -0.00011, Time: 4.33\n",
            "It: 450, Loss: 4.786e+02, l1: 0.001, l2: -0.00022, Time: 4.32\n",
            "It: 460, Loss: 4.779e+02, l1: -0.002, l2: -0.00028, Time: 4.38\n",
            "It: 470, Loss: 4.774e+02, l1: -0.003, l2: -0.00031, Time: 4.37\n",
            "It: 480, Loss: 4.768e+02, l1: -0.004, l2: -0.00031, Time: 4.30\n",
            "It: 490, Loss: 4.764e+02, l1: -0.005, l2: -0.00029, Time: 4.37\n",
            "It: 500, Loss: 4.759e+02, l1: -0.005, l2: -0.00027, Time: 4.33\n",
            "It: 510, Loss: 4.755e+02, l1: -0.006, l2: -0.00025, Time: 4.31\n",
            "It: 520, Loss: 4.752e+02, l1: -0.006, l2: -0.00023, Time: 4.29\n",
            "It: 530, Loss: 4.748e+02, l1: -0.007, l2: -0.00021, Time: 4.30\n",
            "It: 540, Loss: 4.745e+02, l1: -0.007, l2: -0.00019, Time: 4.40\n",
            "It: 550, Loss: 4.743e+02, l1: -0.008, l2: -0.00017, Time: 4.35\n",
            "It: 560, Loss: 4.740e+02, l1: -0.008, l2: -0.00016, Time: 4.31\n",
            "It: 570, Loss: 4.738e+02, l1: -0.009, l2: -0.00015, Time: 4.36\n",
            "It: 580, Loss: 4.735e+02, l1: -0.009, l2: -0.00014, Time: 4.30\n",
            "It: 590, Loss: 4.739e+02, l1: -0.009, l2: -0.00014, Time: 4.29\n",
            "It: 600, Loss: 4.784e+02, l1: -0.010, l2: -0.00012, Time: 4.29\n",
            "It: 610, Loss: 4.732e+02, l1: -0.010, l2: -0.00013, Time: 4.33\n",
            "It: 620, Loss: 4.728e+02, l1: -0.010, l2: -0.00013, Time: 4.29\n",
            "It: 630, Loss: 4.727e+02, l1: -0.010, l2: -0.00013, Time: 4.37\n",
            "It: 640, Loss: 4.725e+02, l1: -0.010, l2: -0.00014, Time: 4.36\n",
            "It: 650, Loss: 4.722e+02, l1: -0.011, l2: -0.00015, Time: 4.34\n",
            "It: 660, Loss: 4.721e+02, l1: -0.011, l2: -0.00016, Time: 4.45\n",
            "It: 670, Loss: 4.719e+02, l1: -0.011, l2: -0.00017, Time: 4.38\n",
            "It: 680, Loss: 4.717e+02, l1: -0.011, l2: -0.00018, Time: 4.32\n",
            "It: 690, Loss: 4.715e+02, l1: -0.011, l2: -0.00019, Time: 4.33\n",
            "It: 700, Loss: 4.714e+02, l1: -0.011, l2: -0.00019, Time: 4.34\n",
            "It: 710, Loss: 4.712e+02, l1: -0.011, l2: -0.00020, Time: 4.35\n",
            "It: 720, Loss: 4.710e+02, l1: -0.011, l2: -0.00021, Time: 4.33\n",
            "It: 730, Loss: 4.708e+02, l1: -0.011, l2: -0.00022, Time: 4.32\n",
            "It: 740, Loss: 4.706e+02, l1: -0.011, l2: -0.00023, Time: 4.38\n",
            "It: 750, Loss: 4.705e+02, l1: -0.011, l2: -0.00024, Time: 4.33\n",
            "It: 760, Loss: 4.703e+02, l1: -0.011, l2: -0.00025, Time: 4.32\n",
            "It: 770, Loss: 4.701e+02, l1: -0.011, l2: -0.00025, Time: 4.33\n",
            "It: 780, Loss: 4.700e+02, l1: -0.011, l2: -0.00026, Time: 4.40\n",
            "It: 790, Loss: 4.698e+02, l1: -0.011, l2: -0.00027, Time: 4.44\n",
            "It: 800, Loss: 4.697e+02, l1: -0.011, l2: -0.00027, Time: 4.30\n",
            "It: 810, Loss: 4.695e+02, l1: -0.011, l2: -0.00027, Time: 4.37\n",
            "It: 820, Loss: 4.694e+02, l1: -0.011, l2: -0.00028, Time: 5.84\n",
            "It: 830, Loss: 4.693e+02, l1: -0.011, l2: -0.00028, Time: 5.93\n",
            "It: 840, Loss: 4.804e+02, l1: -0.010, l2: -0.00029, Time: 4.33\n",
            "It: 850, Loss: 4.711e+02, l1: -0.010, l2: -0.00028, Time: 4.33\n",
            "It: 860, Loss: 4.698e+02, l1: -0.010, l2: -0.00028, Time: 4.35\n",
            "It: 870, Loss: 4.690e+02, l1: -0.010, l2: -0.00028, Time: 4.37\n",
            "It: 880, Loss: 4.690e+02, l1: -0.010, l2: -0.00028, Time: 4.28\n",
            "It: 890, Loss: 4.688e+02, l1: -0.010, l2: -0.00028, Time: 4.40\n",
            "It: 900, Loss: 4.688e+02, l1: -0.010, l2: -0.00029, Time: 4.31\n",
            "It: 910, Loss: 4.687e+02, l1: -0.010, l2: -0.00030, Time: 4.34\n",
            "It: 920, Loss: 4.687e+02, l1: -0.010, l2: -0.00030, Time: 4.40\n",
            "It: 930, Loss: 4.686e+02, l1: -0.010, l2: -0.00030, Time: 4.31\n",
            "It: 940, Loss: 4.685e+02, l1: -0.010, l2: -0.00030, Time: 4.37\n",
            "It: 950, Loss: 4.685e+02, l1: -0.010, l2: -0.00031, Time: 4.31\n",
            "It: 960, Loss: 4.684e+02, l1: -0.010, l2: -0.00031, Time: 4.43\n",
            "It: 970, Loss: 4.684e+02, l1: -0.010, l2: -0.00031, Time: 4.34\n",
            "It: 980, Loss: 4.683e+02, l1: -0.010, l2: -0.00032, Time: 4.47\n",
            "It: 990, Loss: 4.683e+02, l1: -0.010, l2: -0.00032, Time: 4.37\n",
            "It: 1000, Loss: 4.682e+02, l1: -0.011, l2: -0.00032, Time: 4.37\n",
            "It: 1010, Loss: 4.682e+02, l1: -0.011, l2: -0.00033, Time: 4.29\n",
            "It: 1020, Loss: 4.681e+02, l1: -0.011, l2: -0.00033, Time: 6.74\n",
            "It: 1030, Loss: 4.681e+02, l1: -0.011, l2: -0.00033, Time: 4.78\n",
            "It: 1040, Loss: 4.680e+02, l1: -0.011, l2: -0.00034, Time: 4.38\n",
            "It: 1050, Loss: 4.680e+02, l1: -0.011, l2: -0.00034, Time: 4.39\n",
            "It: 1060, Loss: 4.680e+02, l1: -0.011, l2: -0.00034, Time: 4.36\n",
            "It: 1070, Loss: 4.679e+02, l1: -0.011, l2: -0.00035, Time: 4.37\n",
            "It: 1080, Loss: 4.679e+02, l1: -0.012, l2: -0.00035, Time: 4.30\n",
            "It: 1090, Loss: 4.678e+02, l1: -0.012, l2: -0.00035, Time: 4.39\n",
            "It: 1100, Loss: 4.711e+02, l1: -0.012, l2: -0.00035, Time: 4.35\n",
            "It: 1110, Loss: 4.695e+02, l1: -0.012, l2: -0.00037, Time: 4.32\n",
            "It: 1120, Loss: 4.688e+02, l1: -0.012, l2: -0.00037, Time: 4.30\n",
            "It: 1130, Loss: 4.677e+02, l1: -0.012, l2: -0.00037, Time: 4.35\n",
            "It: 1140, Loss: 4.678e+02, l1: -0.012, l2: -0.00037, Time: 6.83\n",
            "It: 1150, Loss: 4.676e+02, l1: -0.012, l2: -0.00037, Time: 4.82\n",
            "It: 1160, Loss: 4.676e+02, l1: -0.013, l2: -0.00038, Time: 4.31\n",
            "It: 1170, Loss: 4.675e+02, l1: -0.013, l2: -0.00039, Time: 4.41\n",
            "It: 1180, Loss: 4.675e+02, l1: -0.013, l2: -0.00040, Time: 4.36\n",
            "It: 1190, Loss: 4.674e+02, l1: -0.013, l2: -0.00040, Time: 4.38\n",
            "It: 1200, Loss: 4.674e+02, l1: -0.013, l2: -0.00040, Time: 4.39\n",
            "It: 1210, Loss: 4.674e+02, l1: -0.013, l2: -0.00040, Time: 4.39\n",
            "It: 1220, Loss: 4.673e+02, l1: -0.014, l2: -0.00041, Time: 4.31\n",
            "It: 1230, Loss: 4.673e+02, l1: -0.014, l2: -0.00041, Time: 4.35\n",
            "It: 1240, Loss: 4.672e+02, l1: -0.014, l2: -0.00041, Time: 4.34\n",
            "It: 1250, Loss: 4.672e+02, l1: -0.014, l2: -0.00042, Time: 4.34\n",
            "It: 1260, Loss: 4.671e+02, l1: -0.014, l2: -0.00042, Time: 7.21\n",
            "It: 1270, Loss: 4.671e+02, l1: -0.014, l2: -0.00042, Time: 4.52\n",
            "It: 1280, Loss: 4.671e+02, l1: -0.014, l2: -0.00043, Time: 5.74\n",
            "It: 1290, Loss: 4.670e+02, l1: -0.015, l2: -0.00043, Time: 5.69\n",
            "It: 1300, Loss: 4.670e+02, l1: -0.015, l2: -0.00043, Time: 4.33\n",
            "It: 1310, Loss: 4.669e+02, l1: -0.015, l2: -0.00043, Time: 4.36\n",
            "It: 1320, Loss: 4.669e+02, l1: -0.015, l2: -0.00044, Time: 4.35\n",
            "It: 1330, Loss: 4.668e+02, l1: -0.015, l2: -0.00044, Time: 4.26\n",
            "It: 1340, Loss: 4.668e+02, l1: -0.015, l2: -0.00044, Time: 4.29\n",
            "It: 1350, Loss: 4.668e+02, l1: -0.015, l2: -0.00045, Time: 4.35\n",
            "It: 1360, Loss: 4.788e+02, l1: -0.015, l2: -0.00048, Time: 4.51\n",
            "It: 1370, Loss: 4.668e+02, l1: -0.015, l2: -0.00047, Time: 6.99\n",
            "It: 1380, Loss: 4.676e+02, l1: -0.016, l2: -0.00048, Time: 4.40\n",
            "It: 1390, Loss: 4.670e+02, l1: -0.016, l2: -0.00047, Time: 4.36\n",
            "It: 1400, Loss: 4.665e+02, l1: -0.016, l2: -0.00047, Time: 4.39\n",
            "It: 1410, Loss: 4.665e+02, l1: -0.016, l2: -0.00048, Time: 4.34\n",
            "It: 1420, Loss: 4.664e+02, l1: -0.017, l2: -0.00050, Time: 4.35\n",
            "It: 1430, Loss: 4.663e+02, l1: -0.017, l2: -0.00050, Time: 4.30\n",
            "It: 1440, Loss: 4.663e+02, l1: -0.017, l2: -0.00051, Time: 4.34\n",
            "It: 1450, Loss: 4.662e+02, l1: -0.017, l2: -0.00051, Time: 4.39\n",
            "It: 1460, Loss: 4.661e+02, l1: -0.017, l2: -0.00052, Time: 4.38\n",
            "It: 1470, Loss: 4.661e+02, l1: -0.018, l2: -0.00052, Time: 4.36\n",
            "It: 1480, Loss: 4.660e+02, l1: -0.018, l2: -0.00053, Time: 5.09\n",
            "It: 1490, Loss: 4.659e+02, l1: -0.018, l2: -0.00053, Time: 6.36\n",
            "It: 1500, Loss: 4.659e+02, l1: -0.018, l2: -0.00054, Time: 4.28\n",
            "It: 1510, Loss: 4.658e+02, l1: -0.018, l2: -0.00054, Time: 4.33\n",
            "It: 1520, Loss: 4.657e+02, l1: -0.019, l2: -0.00055, Time: 4.28\n",
            "It: 1530, Loss: 4.656e+02, l1: -0.019, l2: -0.00056, Time: 4.26\n",
            "It: 1540, Loss: 4.656e+02, l1: -0.019, l2: -0.00056, Time: 4.31\n",
            "It: 1550, Loss: 4.655e+02, l1: -0.020, l2: -0.00057, Time: 4.32\n",
            "It: 1560, Loss: 4.654e+02, l1: -0.020, l2: -0.00058, Time: 4.30\n",
            "It: 1570, Loss: 4.653e+02, l1: -0.020, l2: -0.00059, Time: 4.27\n",
            "It: 1580, Loss: 4.652e+02, l1: -0.020, l2: -0.00059, Time: 4.29\n",
            "It: 1590, Loss: 4.651e+02, l1: -0.021, l2: -0.00060, Time: 4.32\n",
            "It: 1600, Loss: 4.650e+02, l1: -0.021, l2: -0.00061, Time: 4.93\n",
            "It: 1610, Loss: 4.649e+02, l1: -0.022, l2: -0.00062, Time: 6.45\n",
            "It: 1620, Loss: 4.892e+02, l1: -0.022, l2: -0.00073, Time: 4.34\n",
            "It: 1630, Loss: 4.691e+02, l1: -0.022, l2: -0.00060, Time: 4.32\n",
            "It: 1640, Loss: 4.669e+02, l1: -0.023, l2: -0.00071, Time: 4.30\n",
            "It: 1650, Loss: 4.650e+02, l1: -0.023, l2: -0.00064, Time: 4.29\n",
            "It: 1660, Loss: 4.646e+02, l1: -0.023, l2: -0.00069, Time: 4.29\n",
            "It: 1670, Loss: 4.645e+02, l1: -0.024, l2: -0.00072, Time: 5.67\n",
            "It: 1680, Loss: 4.644e+02, l1: -0.025, l2: -0.00073, Time: 4.98\n",
            "It: 1690, Loss: 4.642e+02, l1: -0.025, l2: -0.00075, Time: 4.40\n",
            "It: 1700, Loss: 4.641e+02, l1: -0.026, l2: -0.00076, Time: 4.39\n",
            "It: 1710, Loss: 4.640e+02, l1: -0.026, l2: -0.00078, Time: 5.02\n",
            "It: 1720, Loss: 4.639e+02, l1: -0.027, l2: -0.00079, Time: 6.54\n",
            "It: 1730, Loss: 4.638e+02, l1: -0.027, l2: -0.00080, Time: 4.35\n",
            "It: 1740, Loss: 4.637e+02, l1: -0.028, l2: -0.00081, Time: 4.36\n",
            "It: 1750, Loss: 4.636e+02, l1: -0.029, l2: -0.00083, Time: 7.23\n",
            "It: 1760, Loss: 4.635e+02, l1: -0.029, l2: -0.00084, Time: 4.32\n",
            "It: 1770, Loss: 4.634e+02, l1: -0.030, l2: -0.00085, Time: 4.36\n",
            "It: 1780, Loss: 4.633e+02, l1: -0.030, l2: -0.00087, Time: 4.34\n",
            "It: 1790, Loss: 4.632e+02, l1: -0.031, l2: -0.00088, Time: 4.35\n",
            "It: 1800, Loss: 4.631e+02, l1: -0.032, l2: -0.00089, Time: 4.29\n",
            "It: 1810, Loss: 4.630e+02, l1: -0.032, l2: -0.00091, Time: 4.36\n",
            "It: 1820, Loss: 4.628e+02, l1: -0.033, l2: -0.00092, Time: 5.41\n",
            "It: 1830, Loss: 4.627e+02, l1: -0.033, l2: -0.00093, Time: 5.96\n",
            "It: 1840, Loss: 4.626e+02, l1: -0.034, l2: -0.00094, Time: 4.32\n",
            "It: 1850, Loss: 4.625e+02, l1: -0.034, l2: -0.00096, Time: 4.34\n",
            "It: 1860, Loss: 4.624e+02, l1: -0.035, l2: -0.00097, Time: 4.32\n",
            "It: 1870, Loss: 4.623e+02, l1: -0.036, l2: -0.00098, Time: 4.35\n",
            "It: 1880, Loss: 4.622e+02, l1: -0.036, l2: -0.00099, Time: 4.36\n",
            "It: 1890, Loss: 4.621e+02, l1: -0.037, l2: -0.00100, Time: 4.29\n",
            "It: 1900, Loss: 4.620e+02, l1: -0.037, l2: -0.00101, Time: 4.38\n",
            "It: 1910, Loss: 4.650e+02, l1: -0.037, l2: -0.00098, Time: 4.33\n",
            "It: 1920, Loss: 4.652e+02, l1: -0.037, l2: -0.00116, Time: 4.41\n",
            "It: 1930, Loss: 4.627e+02, l1: -0.038, l2: -0.00105, Time: 4.33\n",
            "It: 1940, Loss: 4.620e+02, l1: -0.038, l2: -0.00107, Time: 7.16\n",
            "It: 1950, Loss: 4.619e+02, l1: -0.037, l2: -0.00107, Time: 4.48\n",
            "It: 1960, Loss: 4.617e+02, l1: -0.038, l2: -0.00107, Time: 4.38\n",
            "It: 1970, Loss: 4.615e+02, l1: -0.039, l2: -0.00111, Time: 4.33\n",
            "It: 1980, Loss: 4.614e+02, l1: -0.039, l2: -0.00110, Time: 4.35\n",
            "It: 1990, Loss: 4.613e+02, l1: -0.039, l2: -0.00111, Time: 4.33\n",
            "It: 2000, Loss: 4.612e+02, l1: -0.039, l2: -0.00110, Time: 4.32\n",
            "It: 2010, Loss: 4.611e+02, l1: -0.039, l2: -0.00109, Time: 4.39\n",
            "It: 2020, Loss: 4.610e+02, l1: -0.039, l2: -0.00109, Time: 4.32\n",
            "It: 2030, Loss: 4.609e+02, l1: -0.039, l2: -0.00108, Time: 4.32\n",
            "It: 2040, Loss: 4.608e+02, l1: -0.039, l2: -0.00107, Time: 4.31\n",
            "It: 2050, Loss: 4.607e+02, l1: -0.039, l2: -0.00107, Time: 4.74\n",
            "It: 2060, Loss: 4.606e+02, l1: -0.039, l2: -0.00106, Time: 6.66\n",
            "It: 2070, Loss: 4.604e+02, l1: -0.039, l2: -0.00105, Time: 4.34\n",
            "It: 2080, Loss: 4.603e+02, l1: -0.038, l2: -0.00104, Time: 4.33\n",
            "It: 2090, Loss: 4.602e+02, l1: -0.038, l2: -0.00102, Time: 4.38\n",
            "It: 2100, Loss: 4.601e+02, l1: -0.037, l2: -0.00101, Time: 4.39\n",
            "It: 2110, Loss: 4.600e+02, l1: -0.037, l2: -0.00100, Time: 4.34\n",
            "It: 2120, Loss: 4.599e+02, l1: -0.036, l2: -0.00098, Time: 4.35\n",
            "It: 2130, Loss: 4.597e+02, l1: -0.036, l2: -0.00096, Time: 4.36\n",
            "It: 2140, Loss: 4.596e+02, l1: -0.035, l2: -0.00094, Time: 4.40\n",
            "It: 2150, Loss: 4.595e+02, l1: -0.034, l2: -0.00092, Time: 4.38\n",
            "It: 2160, Loss: 4.593e+02, l1: -0.034, l2: -0.00090, Time: 4.32\n",
            "It: 2170, Loss: 4.592e+02, l1: -0.033, l2: -0.00087, Time: 5.44\n",
            "It: 2180, Loss: 4.590e+02, l1: -0.032, l2: -0.00085, Time: 5.94\n",
            "It: 2190, Loss: 4.607e+02, l1: -0.031, l2: -0.00079, Time: 4.34\n",
            "It: 2200, Loss: 4.692e+02, l1: -0.029, l2: -0.00093, Time: 6.67\n",
            "It: 2210, Loss: 4.631e+02, l1: -0.029, l2: -0.00075, Time: 4.84\n",
            "It: 2220, Loss: 4.596e+02, l1: -0.028, l2: -0.00082, Time: 4.31\n",
            "It: 2230, Loss: 4.586e+02, l1: -0.026, l2: -0.00076, Time: 4.32\n",
            "It: 2240, Loss: 4.584e+02, l1: -0.026, l2: -0.00078, Time: 4.34\n",
            "It: 2250, Loss: 4.583e+02, l1: -0.025, l2: -0.00073, Time: 4.33\n",
            "It: 2260, Loss: 4.581e+02, l1: -0.024, l2: -0.00070, Time: 4.33\n",
            "It: 2270, Loss: 4.580e+02, l1: -0.023, l2: -0.00064, Time: 4.32\n",
            "It: 2280, Loss: 4.579e+02, l1: -0.022, l2: -0.00061, Time: 5.11\n",
            "It: 2290, Loss: 4.577e+02, l1: -0.020, l2: -0.00056, Time: 6.44\n",
            "It: 2300, Loss: 4.576e+02, l1: -0.019, l2: -0.00052, Time: 4.40\n",
            "It: 2310, Loss: 4.574e+02, l1: -0.017, l2: -0.00048, Time: 4.37\n",
            "It: 2320, Loss: 4.573e+02, l1: -0.016, l2: -0.00044, Time: 4.31\n",
            "It: 2330, Loss: 4.572e+02, l1: -0.014, l2: -0.00039, Time: 4.34\n",
            "It: 2340, Loss: 4.570e+02, l1: -0.012, l2: -0.00035, Time: 4.35\n",
            "It: 2350, Loss: 4.569e+02, l1: -0.011, l2: -0.00030, Time: 4.36\n",
            "It: 2360, Loss: 4.567e+02, l1: -0.009, l2: -0.00026, Time: 4.35\n",
            "It: 2370, Loss: 4.566e+02, l1: -0.007, l2: -0.00021, Time: 4.35\n",
            "It: 2380, Loss: 4.565e+02, l1: -0.005, l2: -0.00016, Time: 4.33\n",
            "It: 2390, Loss: 4.563e+02, l1: -0.003, l2: -0.00011, Time: 4.32\n",
            "It: 2400, Loss: 4.562e+02, l1: -0.001, l2: -0.00006, Time: 6.94\n",
            "It: 2410, Loss: 4.561e+02, l1: 0.001, l2: -0.00001, Time: 4.50\n",
            "It: 2420, Loss: 4.559e+02, l1: 0.003, l2: 0.00004, Time: 4.38\n",
            "It: 2430, Loss: 4.558e+02, l1: 0.005, l2: 0.00009, Time: 4.34\n",
            "It: 2440, Loss: 4.557e+02, l1: 0.007, l2: 0.00013, Time: 4.31\n",
            "It: 2450, Loss: 4.557e+02, l1: 0.009, l2: 0.00018, Time: 4.37\n",
            "It: 2460, Loss: 4.615e+02, l1: 0.010, l2: 0.00018, Time: 4.34\n",
            "It: 2470, Loss: 4.598e+02, l1: 0.012, l2: 0.00028, Time: 4.34\n",
            "It: 2480, Loss: 4.571e+02, l1: 0.012, l2: 0.00015, Time: 4.31\n",
            "It: 2490, Loss: 4.557e+02, l1: 0.014, l2: 0.00028, Time: 4.36\n",
            "It: 2500, Loss: 4.553e+02, l1: 0.015, l2: 0.00025, Time: 4.30\n",
            "It: 2510, Loss: 4.551e+02, l1: 0.017, l2: 0.00033, Time: 4.50\n",
            "It: 2520, Loss: 4.549e+02, l1: 0.018, l2: 0.00037, Time: 7.09\n",
            "It: 2530, Loss: 4.548e+02, l1: 0.020, l2: 0.00042, Time: 4.33\n",
            "It: 2540, Loss: 4.547e+02, l1: 0.022, l2: 0.00046, Time: 4.34\n",
            "It: 2550, Loss: 4.546e+02, l1: 0.023, l2: 0.00050, Time: 4.34\n",
            "It: 2560, Loss: 4.545e+02, l1: 0.025, l2: 0.00053, Time: 4.36\n",
            "It: 2570, Loss: 4.544e+02, l1: 0.026, l2: 0.00057, Time: 4.33\n",
            "It: 2580, Loss: 4.543e+02, l1: 0.028, l2: 0.00060, Time: 4.38\n",
            "It: 2590, Loss: 4.542e+02, l1: 0.029, l2: 0.00064, Time: 4.36\n",
            "It: 2600, Loss: 4.541e+02, l1: 0.030, l2: 0.00067, Time: 4.38\n",
            "It: 2610, Loss: 4.540e+02, l1: 0.032, l2: 0.00070, Time: 4.33\n",
            "It: 2620, Loss: 4.539e+02, l1: 0.033, l2: 0.00073, Time: 4.30\n",
            "It: 2630, Loss: 4.538e+02, l1: 0.034, l2: 0.00076, Time: 5.18\n",
            "It: 2640, Loss: 4.537e+02, l1: 0.035, l2: 0.00079, Time: 6.29\n",
            "It: 2650, Loss: 4.536e+02, l1: 0.037, l2: 0.00082, Time: 6.00\n",
            "It: 2660, Loss: 4.535e+02, l1: 0.038, l2: 0.00084, Time: 5.45\n",
            "It: 2670, Loss: 4.534e+02, l1: 0.039, l2: 0.00087, Time: 4.37\n",
            "It: 2680, Loss: 4.533e+02, l1: 0.040, l2: 0.00090, Time: 4.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHH94r3ibrkk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}