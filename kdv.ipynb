{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvejlt7DeV30V3Ixj19GV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amiralizadeh1/PINNs/blob/master/kdv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTQfySYB1osU",
        "outputId": "2d670d5c-5e65-44c7-a77e-bcf33f54f818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 49 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (2.0.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.50.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow==1.14.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "print(tf.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llBWTtll1taX",
        "outputId": "64c4fc94-b60e-4400-95b9-fdef2f0c8ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'tensorflow._api.v1.version' from '/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v1/version/__init__.py'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@author: Maziar Raissi\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/Utilities') #upload utilities folder to your google drive before running the lines\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import scipy.io\n",
        "from plotting import newfig, savefig\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "\n",
        "class PhysicsInformedNN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, x0, u0, x1, u1, layers, dt, lb, ub, q):\n",
        "        \n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "        \n",
        "        self.x0 = x0\n",
        "        self.x1 = x1\n",
        "        \n",
        "        self.u0 = u0\n",
        "        self.u1 = u1\n",
        "        \n",
        "        self.layers = layers\n",
        "        self.dt = dt\n",
        "        self.q = max(q,1)\n",
        "    \n",
        "        # Initialize NN\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # Initialize parameters\n",
        "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
        "        self.lambda_2 = tf.Variable([-6.0], dtype=tf.float32)       \n",
        "        \n",
        "        # Load IRK weights\n",
        "        tmp = np.float32(np.loadtxt('../content/drive/MyDrive/Utilities/IRK_weights/Butcher_IRK%d.txt' % (q), ndmin = 2))\n",
        "        weights =  np.reshape(tmp[0:q**2+q], (q+1,q))     \n",
        "        self.IRK_alpha = weights[0:-1,:]\n",
        "        self.IRK_beta = weights[-1:,:]        \n",
        "        self.IRK_times = tmp[q**2+q:]\n",
        "        \n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        self.x0_tf = tf.placeholder(tf.float32, shape=(None, self.x0.shape[1]))\n",
        "        self.x1_tf = tf.placeholder(tf.float32, shape=(None, self.x1.shape[1]))\n",
        "        self.u0_tf = tf.placeholder(tf.float32, shape=(None, self.u0.shape[1]))\n",
        "        self.u1_tf = tf.placeholder(tf.float32, shape=(None, self.u1.shape[1]))\n",
        "        self.dummy_x0_tf = tf.placeholder(tf.float32, shape=(None, self.q)) # dummy variable for fwd_gradients        \n",
        "        self.dummy_x1_tf = tf.placeholder(tf.float32, shape=(None, self.q)) # dummy variable for fwd_gradients        \n",
        "        \n",
        "        self.U0_pred = self.net_U0(self.x0_tf) # N0 x q\n",
        "        self.U1_pred = self.net_U1(self.x1_tf) # N1 x q\n",
        "        \n",
        "        self.loss = tf.reduce_sum(tf.square(self.u0_tf - self.U0_pred)) + \\\n",
        "                    tf.reduce_sum(tf.square(self.u1_tf - self.U1_pred)) \n",
        "        \n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 50000,\n",
        "                                                                           'maxfun': 50000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0 * np.finfo(float).eps})        \n",
        "        \n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "        \n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)        \n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]        \n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "    \n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "    \n",
        "    def fwd_gradients_0(self, U, x):        \n",
        "        g = tf.gradients(U, x, grad_ys=self.dummy_x0_tf)[0]\n",
        "        return tf.gradients(g, self.dummy_x0_tf)[0]\n",
        "    \n",
        "    def fwd_gradients_1(self, U, x):        \n",
        "        g = tf.gradients(U, x, grad_ys=self.dummy_x1_tf)[0]\n",
        "        return tf.gradients(g, self.dummy_x1_tf)[0]    \n",
        "    \n",
        "    def net_U0(self, x):\n",
        "        lambda_1 = self.lambda_1\n",
        "        lambda_2 = tf.exp(self.lambda_2)\n",
        "        U = self.neural_net(x, self.weights, self.biases)        \n",
        "        U_x = self.fwd_gradients_0(U, x)\n",
        "        U_xx = self.fwd_gradients_0(U_x, x)\n",
        "        U_xxx = self.fwd_gradients_0(U_xx, x)        \n",
        "        F = -lambda_1*U*U_x - lambda_2*U_xxx\n",
        "        U0 = U - self.dt*tf.matmul(F, self.IRK_alpha.T)\n",
        "        return U0\n",
        "    \n",
        "    def net_U1(self, x):\n",
        "        lambda_1 = self.lambda_1\n",
        "        lambda_2 = tf.exp(self.lambda_2)\n",
        "        U = self.neural_net(x, self.weights, self.biases)        \n",
        "        U_x = self.fwd_gradients_1(U, x)\n",
        "        U_xx = self.fwd_gradients_1(U_x, x)\n",
        "        U_xxx = self.fwd_gradients_1(U_xx, x)        \n",
        "        F = -lambda_1*U*U_x - lambda_2*U_xxx\n",
        "        U1 = U + self.dt*tf.matmul(F, (self.IRK_beta - self.IRK_alpha).T)\n",
        "        return U1\n",
        "\n",
        "    def callback(self, loss):\n",
        "        print('Loss:', loss)\n",
        "    \n",
        "    def train(self, nIter):\n",
        "        tf_dict = {self.x0_tf: self.x0, self.u0_tf: self.u0, \n",
        "                   self.x1_tf: self.x1, self.u1_tf: self.u1,\n",
        "                   self.dummy_x0_tf: np.ones((self.x0.shape[0], self.q)),\n",
        "                   self.dummy_x1_tf: np.ones((self.x1.shape[0], self.q))}\n",
        "                           \n",
        "        start_time = time.time()\n",
        "        for it in range(nIter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                lambda_1_value = self.sess.run(self.lambda_1)\n",
        "                lambda_2_value = np.exp(self.sess.run(self.lambda_2))\n",
        "                print('It: %d, Loss: %.3e, l1: %.3f, l2: %.5f, Time: %.2f' % \n",
        "                      (it, loss_value, lambda_1_value, lambda_2_value, elapsed))\n",
        "                start_time = time.time()\n",
        "    \n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict = tf_dict,\n",
        "                                fetches = [self.loss],\n",
        "                                loss_callback = self.callback)\n",
        "    \n",
        "    def predict(self, x_star):\n",
        "        \n",
        "        U0_star = self.sess.run(self.U0_pred, {self.x0_tf: x_star, self.dummy_x0_tf: np.ones((x_star.shape[0], self.q))})        \n",
        "        U1_star = self.sess.run(self.U1_pred, {self.x1_tf: x_star, self.dummy_x1_tf: np.ones((x_star.shape[0], self.q))})\n",
        "                    \n",
        "        return U0_star, U1_star\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\": \n",
        "        \n",
        "    q = 50\n",
        "    skip = 120\n",
        "\n",
        "    N0 = 199\n",
        "    N1 = 201\n",
        "    layers = [1, 50, 50, 50, 50, q]\n",
        "    \n",
        "    data = scipy.io.loadmat('../content/drive/MyDrive/Data/KdV.mat')\n",
        "    \n",
        "    t_star = data['tt'].flatten()[:,None]\n",
        "    x_star = data['x'].flatten()[:,None]\n",
        "    Exact = np.real(data['uu'])\n",
        "    \n",
        "    idx_t = 40\n",
        "        \n",
        "    ######################################################################\n",
        "    ######################## Noiseles Data ###############################\n",
        "    ######################################################################\n",
        "    noise = 0.0    \n",
        "    \n",
        "    idx_x = np.random.choice(Exact.shape[0], N0, replace=False)\n",
        "    x0 = x_star[idx_x,:]\n",
        "    u0 = Exact[idx_x,idx_t][:,None]\n",
        "    u0 = u0 + noise*np.std(u0)*np.random.randn(u0.shape[0], u0.shape[1])\n",
        "        \n",
        "    idx_x = np.random.choice(Exact.shape[0], N1, replace=False)\n",
        "    x1 = x_star[idx_x,:]\n",
        "    u1 = Exact[idx_x,idx_t + skip][:,None]\n",
        "    u1 = u1 + noise*np.std(u1)*np.random.randn(u1.shape[0], u1.shape[1])\n",
        "    \n",
        "    dt = np.asscalar(t_star[idx_t+skip] - t_star[idx_t])        \n",
        "        \n",
        "    # Doman bounds\n",
        "    lb = x_star.min(0)\n",
        "    ub = x_star.max(0)\n",
        "\n",
        "    model = PhysicsInformedNN(x0, u0, x1, u1, layers, dt, lb, ub, q)\n",
        "    model.train(nIter = 50000)\n",
        "    \n",
        "    U0_pred, U1_pred = model.predict(x_star)    \n",
        "        \n",
        "    lambda_1_value = model.sess.run(model.lambda_1)\n",
        "    lambda_2_value = np.exp(model.sess.run(model.lambda_2))\n",
        "                \n",
        "    error_lambda_1 = np.abs(lambda_1_value - 1.0)/1.0 *100\n",
        "    error_lambda_2 = np.abs(lambda_2_value - 0.0025)/0.0025 * 100\n",
        "    \n",
        "    print('Error lambda_1: %f%%' % (error_lambda_1))\n",
        "    print('Error lambda_2: %f%%' % (error_lambda_2))\n",
        "    \n",
        "    \n",
        "    ######################################################################\n",
        "    ########################### Noisy Data ###############################\n",
        "    ######################################################################\n",
        "    noise = 0.01        \n",
        "    \n",
        "    u0 = u0 + noise*np.std(u0)*np.random.randn(u0.shape[0], u0.shape[1])\n",
        "    u1 = u1 + noise*np.std(u1)*np.random.randn(u1.shape[0], u1.shape[1])\n",
        "    \n",
        "    model = PhysicsInformedNN(x0, u0, x1, u1, layers, dt, lb, ub, q)    \n",
        "    model.train(nIter = 50000)\n",
        "    \n",
        "    U_pred = model.predict(x_star)\n",
        "    \n",
        "    U0_pred, U1_pred = model.predict(x_star)    \n",
        "        \n",
        "    lambda_1_value_noisy = model.sess.run(model.lambda_1)\n",
        "    lambda_2_value_noisy = np.exp(model.sess.run(model.lambda_2))\n",
        "                \n",
        "    error_lambda_1_noisy = np.abs(lambda_1_value_noisy - 1.0)/1.0 *100\n",
        "    error_lambda_2_noisy = np.abs(lambda_2_value_noisy - 0.0025)/0.0025 * 100\n",
        "    \n",
        "    print('Error lambda_1: %f%%' % (error_lambda_1_noisy))\n",
        "    print('Error lambda_2: %f%%' % (error_lambda_2_noisy))\n",
        "    \n",
        "    ######################################################################\n",
        "    ############################# Plotting ###############################\n",
        "    ######################################################################\n",
        "    \n",
        "    fig, ax = newfig(1.0, 1.5)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    gs0 = gridspec.GridSpec(1, 2)\n",
        "    gs0.update(top=1-0.06, bottom=1-1/3+0.05, left=0.15, right=0.85, wspace=0)\n",
        "    ax = plt.subplot(gs0[:, :])\n",
        "        \n",
        "    h = ax.imshow(Exact, interpolation='nearest', cmap='rainbow',\n",
        "                  extent=[t_star.min(),t_star.max(), lb[0], ub[0]],\n",
        "                  origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    \n",
        "    line = np.linspace(x_star.min(), x_star.max(), 2)[:,None]\n",
        "    ax.plot(t_star[idx_t]*np.ones((2,1)), line, 'w-', linewidth = 1.0)\n",
        "    ax.plot(t_star[idx_t + skip]*np.ones((2,1)), line, 'w-', linewidth = 1.0)    \n",
        "    ax.set_xlabel('$t$')\n",
        "    ax.set_ylabel('$x$')\n",
        "    ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "    \n",
        "    gs1 = gridspec.GridSpec(1, 2)\n",
        "    gs1.update(top=1-1/3-0.1, bottom=1-2/3, left=0.15, right=0.85, wspace=0.5)\n",
        "\n",
        "    ax = plt.subplot(gs1[0, 0])\n",
        "    ax.plot(x_star,Exact[:,idx_t][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "    ax.plot(x0, u0, 'rx', linewidth = 2, label = 'Data')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t], u0.shape[0]), fontsize = 10)\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 1])\n",
        "    ax.plot(x_star,Exact[:,idx_t + skip][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "    ax.plot(x1, u1, 'rx', linewidth = 2, label = 'Data')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t+skip], u1.shape[0]), fontsize = 10)\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(-0.3, -0.3), ncol=2, frameon=False)\n",
        "    \n",
        "    gs2 = gridspec.GridSpec(1, 2)\n",
        "    gs2.update(top=1-2/3-0.05, bottom=0, left=0.15, right=0.85, wspace=0.0)\n",
        "    \n",
        "    ax = plt.subplot(gs2[0, 0])\n",
        "    ax.axis('off')\n",
        "    s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x + 0.0025 u_{xxx} = 0$ \\\\  \\hline Identified PDE (clean data) & '\n",
        "    s2 = r'$u_t + %.3f u u_x + %.7f u_{xxx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "    s3 = r'Identified PDE (1\\% noise) & '\n",
        "    s4 = r'$u_t + %.3f u u_x + %.7f u_{xxx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "    s5 = r'\\end{tabular}$'\n",
        "    s = s1+s2+s3+s4+s5\n",
        "    ax.text(-0.1,0.2,s)\n",
        "\n",
        "    # savefig('./figures/KdV') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfHerGce2ihV",
        "outputId": "e0a70933-6e7f-447f-f115-a648ba3591b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:214: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It: 0, Loss: 1.027e+04, l1: -0.001, l2: 0.00248, Time: 5.33\n",
            "It: 10, Loss: 1.017e+04, l1: -0.009, l2: 0.00251, Time: 0.18\n",
            "It: 20, Loss: 1.014e+04, l1: -0.019, l2: 0.00253, Time: 0.17\n",
            "It: 30, Loss: 1.010e+04, l1: -0.031, l2: 0.00256, Time: 0.18\n",
            "It: 40, Loss: 9.904e+03, l1: -0.045, l2: 0.00260, Time: 0.17\n",
            "It: 50, Loss: 8.994e+03, l1: -0.061, l2: 0.00261, Time: 0.17\n",
            "It: 60, Loss: 6.750e+03, l1: -0.078, l2: 0.00258, Time: 0.17\n",
            "It: 70, Loss: 5.105e+03, l1: -0.075, l2: 0.00253, Time: 0.17\n",
            "It: 80, Loss: 4.706e+03, l1: -0.057, l2: 0.00248, Time: 0.17\n",
            "It: 90, Loss: 4.611e+03, l1: -0.037, l2: 0.00243, Time: 0.16\n",
            "It: 100, Loss: 4.491e+03, l1: -0.020, l2: 0.00238, Time: 0.17\n",
            "It: 110, Loss: 4.406e+03, l1: -0.003, l2: 0.00234, Time: 0.17\n",
            "It: 120, Loss: 4.323e+03, l1: 0.012, l2: 0.00231, Time: 0.17\n",
            "It: 130, Loss: 4.225e+03, l1: 0.027, l2: 0.00227, Time: 0.16\n",
            "It: 140, Loss: 4.110e+03, l1: 0.041, l2: 0.00224, Time: 0.18\n",
            "It: 150, Loss: 3.984e+03, l1: 0.056, l2: 0.00221, Time: 0.16\n",
            "It: 160, Loss: 3.861e+03, l1: 0.070, l2: 0.00217, Time: 0.16\n",
            "It: 170, Loss: 3.756e+03, l1: 0.085, l2: 0.00214, Time: 0.16\n",
            "It: 180, Loss: 3.643e+03, l1: 0.099, l2: 0.00211, Time: 0.16\n",
            "It: 190, Loss: 3.517e+03, l1: 0.114, l2: 0.00208, Time: 0.17\n",
            "It: 200, Loss: 3.377e+03, l1: 0.130, l2: 0.00205, Time: 0.18\n",
            "It: 210, Loss: 3.228e+03, l1: 0.146, l2: 0.00202, Time: 0.17\n",
            "It: 220, Loss: 3.078e+03, l1: 0.163, l2: 0.00199, Time: 0.16\n",
            "It: 230, Loss: 2.913e+03, l1: 0.180, l2: 0.00196, Time: 0.16\n",
            "It: 240, Loss: 2.757e+03, l1: 0.199, l2: 0.00193, Time: 0.16\n",
            "It: 250, Loss: 2.617e+03, l1: 0.217, l2: 0.00190, Time: 0.17\n",
            "It: 260, Loss: 2.486e+03, l1: 0.235, l2: 0.00187, Time: 0.18\n",
            "It: 270, Loss: 2.349e+03, l1: 0.252, l2: 0.00184, Time: 0.16\n",
            "It: 280, Loss: 2.206e+03, l1: 0.268, l2: 0.00182, Time: 0.16\n",
            "It: 290, Loss: 2.057e+03, l1: 0.284, l2: 0.00180, Time: 0.17\n",
            "It: 300, Loss: 1.901e+03, l1: 0.300, l2: 0.00178, Time: 0.17\n",
            "It: 310, Loss: 1.763e+03, l1: 0.315, l2: 0.00176, Time: 0.18\n",
            "It: 320, Loss: 1.648e+03, l1: 0.330, l2: 0.00174, Time: 0.18\n",
            "It: 330, Loss: 1.536e+03, l1: 0.344, l2: 0.00173, Time: 0.16\n",
            "It: 340, Loss: 1.444e+03, l1: 0.358, l2: 0.00171, Time: 0.17\n",
            "It: 350, Loss: 1.366e+03, l1: 0.371, l2: 0.00170, Time: 0.16\n",
            "It: 360, Loss: 1.298e+03, l1: 0.383, l2: 0.00169, Time: 0.17\n",
            "It: 370, Loss: 1.249e+03, l1: 0.394, l2: 0.00168, Time: 0.16\n",
            "It: 380, Loss: 1.191e+03, l1: 0.405, l2: 0.00167, Time: 0.17\n",
            "It: 390, Loss: 1.151e+03, l1: 0.415, l2: 0.00167, Time: 0.16\n",
            "It: 400, Loss: 1.113e+03, l1: 0.424, l2: 0.00166, Time: 0.16\n",
            "It: 410, Loss: 1.087e+03, l1: 0.433, l2: 0.00166, Time: 0.16\n",
            "It: 420, Loss: 1.052e+03, l1: 0.441, l2: 0.00166, Time: 0.17\n",
            "It: 430, Loss: 1.020e+03, l1: 0.449, l2: 0.00165, Time: 0.17\n",
            "It: 440, Loss: 9.966e+02, l1: 0.456, l2: 0.00165, Time: 0.19\n",
            "It: 450, Loss: 9.675e+02, l1: 0.463, l2: 0.00165, Time: 0.17\n",
            "It: 460, Loss: 9.515e+02, l1: 0.470, l2: 0.00165, Time: 0.17\n",
            "It: 470, Loss: 9.248e+02, l1: 0.477, l2: 0.00165, Time: 0.16\n",
            "It: 480, Loss: 9.085e+02, l1: 0.483, l2: 0.00166, Time: 0.16\n",
            "It: 490, Loss: 8.895e+02, l1: 0.489, l2: 0.00166, Time: 0.18\n",
            "It: 500, Loss: 8.731e+02, l1: 0.495, l2: 0.00166, Time: 0.18\n",
            "It: 510, Loss: 8.563e+02, l1: 0.500, l2: 0.00166, Time: 0.17\n",
            "It: 520, Loss: 8.419e+02, l1: 0.506, l2: 0.00167, Time: 0.17\n",
            "It: 530, Loss: 8.478e+02, l1: 0.511, l2: 0.00167, Time: 0.17\n",
            "It: 540, Loss: 8.438e+02, l1: 0.516, l2: 0.00167, Time: 0.17\n",
            "It: 550, Loss: 8.082e+02, l1: 0.521, l2: 0.00168, Time: 0.18\n",
            "It: 560, Loss: 7.887e+02, l1: 0.526, l2: 0.00168, Time: 0.17\n",
            "It: 570, Loss: 7.751e+02, l1: 0.530, l2: 0.00169, Time: 0.25\n",
            "It: 580, Loss: 7.623e+02, l1: 0.535, l2: 0.00169, Time: 0.29\n",
            "It: 590, Loss: 7.488e+02, l1: 0.539, l2: 0.00170, Time: 0.28\n",
            "It: 600, Loss: 7.356e+02, l1: 0.544, l2: 0.00170, Time: 0.32\n",
            "It: 610, Loss: 7.219e+02, l1: 0.548, l2: 0.00171, Time: 0.32\n",
            "It: 620, Loss: 7.082e+02, l1: 0.553, l2: 0.00172, Time: 0.31\n",
            "It: 630, Loss: 6.975e+02, l1: 0.557, l2: 0.00172, Time: 0.43\n",
            "It: 640, Loss: 6.891e+02, l1: 0.561, l2: 0.00173, Time: 0.60\n",
            "It: 650, Loss: 6.678e+02, l1: 0.565, l2: 0.00174, Time: 0.32\n",
            "It: 660, Loss: 6.545e+02, l1: 0.568, l2: 0.00174, Time: 0.16\n",
            "It: 670, Loss: 6.387e+02, l1: 0.572, l2: 0.00175, Time: 0.17\n",
            "It: 680, Loss: 6.226e+02, l1: 0.576, l2: 0.00176, Time: 0.17\n",
            "It: 690, Loss: 6.068e+02, l1: 0.580, l2: 0.00177, Time: 0.17\n",
            "It: 700, Loss: 5.924e+02, l1: 0.584, l2: 0.00177, Time: 0.17\n",
            "It: 710, Loss: 5.778e+02, l1: 0.588, l2: 0.00178, Time: 0.16\n",
            "It: 720, Loss: 5.775e+02, l1: 0.591, l2: 0.00179, Time: 0.16\n",
            "It: 730, Loss: 5.499e+02, l1: 0.595, l2: 0.00180, Time: 0.17\n",
            "It: 740, Loss: 5.334e+02, l1: 0.598, l2: 0.00180, Time: 0.18\n",
            "It: 750, Loss: 5.191e+02, l1: 0.602, l2: 0.00181, Time: 0.17\n",
            "It: 760, Loss: 5.056e+02, l1: 0.605, l2: 0.00182, Time: 0.16\n",
            "It: 770, Loss: 4.919e+02, l1: 0.609, l2: 0.00182, Time: 0.17\n",
            "It: 780, Loss: 4.791e+02, l1: 0.613, l2: 0.00183, Time: 0.16\n",
            "It: 790, Loss: 5.179e+02, l1: 0.616, l2: 0.00184, Time: 0.17\n",
            "It: 800, Loss: 4.881e+02, l1: 0.619, l2: 0.00185, Time: 0.18\n",
            "It: 810, Loss: 4.507e+02, l1: 0.623, l2: 0.00185, Time: 0.17\n",
            "It: 820, Loss: 4.451e+02, l1: 0.626, l2: 0.00186, Time: 0.16\n",
            "It: 830, Loss: 4.341e+02, l1: 0.629, l2: 0.00187, Time: 0.17\n",
            "It: 840, Loss: 4.259e+02, l1: 0.633, l2: 0.00187, Time: 0.17\n",
            "It: 850, Loss: 4.171e+02, l1: 0.636, l2: 0.00188, Time: 0.17\n",
            "It: 860, Loss: 4.085e+02, l1: 0.639, l2: 0.00189, Time: 0.17\n",
            "It: 870, Loss: 4.007e+02, l1: 0.643, l2: 0.00189, Time: 0.17\n",
            "It: 880, Loss: 4.051e+02, l1: 0.646, l2: 0.00190, Time: 0.16\n",
            "It: 890, Loss: 3.877e+02, l1: 0.649, l2: 0.00190, Time: 0.16\n",
            "It: 900, Loss: 3.791e+02, l1: 0.652, l2: 0.00191, Time: 0.16\n",
            "It: 910, Loss: 3.687e+02, l1: 0.656, l2: 0.00192, Time: 0.17\n",
            "It: 920, Loss: 3.590e+02, l1: 0.659, l2: 0.00192, Time: 0.21\n",
            "It: 930, Loss: 3.793e+02, l1: 0.662, l2: 0.00193, Time: 0.16\n",
            "It: 940, Loss: 3.619e+02, l1: 0.665, l2: 0.00194, Time: 0.17\n",
            "It: 950, Loss: 3.436e+02, l1: 0.668, l2: 0.00194, Time: 0.17\n",
            "It: 960, Loss: 3.274e+02, l1: 0.671, l2: 0.00195, Time: 0.17\n",
            "It: 970, Loss: 3.192e+02, l1: 0.675, l2: 0.00195, Time: 0.18\n",
            "It: 980, Loss: 3.104e+02, l1: 0.678, l2: 0.00196, Time: 0.17\n",
            "It: 990, Loss: 3.016e+02, l1: 0.681, l2: 0.00197, Time: 0.17\n",
            "It: 1000, Loss: 3.085e+02, l1: 0.684, l2: 0.00197, Time: 0.17\n",
            "It: 1010, Loss: 3.242e+02, l1: 0.687, l2: 0.00198, Time: 0.16\n",
            "It: 1020, Loss: 2.941e+02, l1: 0.690, l2: 0.00198, Time: 0.17\n",
            "It: 1030, Loss: 2.785e+02, l1: 0.693, l2: 0.00199, Time: 0.19\n",
            "It: 1040, Loss: 2.679e+02, l1: 0.696, l2: 0.00199, Time: 0.17\n",
            "It: 1050, Loss: 2.614e+02, l1: 0.699, l2: 0.00200, Time: 0.17\n",
            "It: 1060, Loss: 2.552e+02, l1: 0.702, l2: 0.00200, Time: 0.17\n",
            "It: 1070, Loss: 2.501e+02, l1: 0.705, l2: 0.00201, Time: 0.16\n",
            "It: 1080, Loss: 2.451e+02, l1: 0.708, l2: 0.00201, Time: 0.17\n",
            "It: 1090, Loss: 2.644e+02, l1: 0.710, l2: 0.00202, Time: 0.18\n",
            "It: 1100, Loss: 2.785e+02, l1: 0.713, l2: 0.00203, Time: 0.16\n",
            "It: 1110, Loss: 2.420e+02, l1: 0.716, l2: 0.00203, Time: 0.16\n",
            "It: 1120, Loss: 2.305e+02, l1: 0.718, l2: 0.00203, Time: 0.16\n",
            "It: 1130, Loss: 2.267e+02, l1: 0.721, l2: 0.00204, Time: 0.16\n",
            "It: 1140, Loss: 2.236e+02, l1: 0.724, l2: 0.00204, Time: 0.17\n",
            "It: 1150, Loss: 2.195e+02, l1: 0.726, l2: 0.00205, Time: 0.18\n",
            "It: 1160, Loss: 2.166e+02, l1: 0.729, l2: 0.00205, Time: 0.16\n",
            "It: 1170, Loss: 2.149e+02, l1: 0.731, l2: 0.00206, Time: 0.18\n",
            "It: 1180, Loss: 2.223e+02, l1: 0.734, l2: 0.00206, Time: 0.16\n",
            "It: 1190, Loss: 2.156e+02, l1: 0.737, l2: 0.00207, Time: 0.17\n",
            "It: 1200, Loss: 2.073e+02, l1: 0.739, l2: 0.00207, Time: 0.18\n",
            "It: 1210, Loss: 2.043e+02, l1: 0.742, l2: 0.00208, Time: 0.17\n",
            "It: 1220, Loss: 2.885e+02, l1: 0.744, l2: 0.00208, Time: 0.16\n",
            "It: 1230, Loss: 2.105e+02, l1: 0.746, l2: 0.00209, Time: 0.17\n",
            "It: 1240, Loss: 2.007e+02, l1: 0.748, l2: 0.00209, Time: 0.16\n",
            "It: 1250, Loss: 1.951e+02, l1: 0.751, l2: 0.00210, Time: 0.17\n",
            "It: 1260, Loss: 1.930e+02, l1: 0.753, l2: 0.00210, Time: 0.18\n",
            "It: 1270, Loss: 1.906e+02, l1: 0.755, l2: 0.00211, Time: 0.17\n",
            "It: 1280, Loss: 1.886e+02, l1: 0.757, l2: 0.00211, Time: 0.17\n",
            "It: 1290, Loss: 1.864e+02, l1: 0.760, l2: 0.00211, Time: 0.17\n",
            "It: 1300, Loss: 1.844e+02, l1: 0.762, l2: 0.00212, Time: 0.16\n",
            "It: 1310, Loss: 1.827e+02, l1: 0.764, l2: 0.00212, Time: 0.17\n",
            "It: 1320, Loss: 1.927e+02, l1: 0.766, l2: 0.00213, Time: 0.17\n",
            "It: 1330, Loss: 1.862e+02, l1: 0.769, l2: 0.00213, Time: 0.17\n",
            "It: 1340, Loss: 1.782e+02, l1: 0.770, l2: 0.00214, Time: 0.17\n",
            "It: 1350, Loss: 1.770e+02, l1: 0.772, l2: 0.00214, Time: 0.17\n",
            "It: 1360, Loss: 1.765e+02, l1: 0.774, l2: 0.00214, Time: 0.16\n",
            "It: 1370, Loss: 1.727e+02, l1: 0.776, l2: 0.00215, Time: 0.17\n",
            "It: 1380, Loss: 1.714e+02, l1: 0.778, l2: 0.00215, Time: 0.17\n",
            "It: 1390, Loss: 1.697e+02, l1: 0.780, l2: 0.00216, Time: 0.17\n",
            "It: 1400, Loss: 1.680e+02, l1: 0.782, l2: 0.00216, Time: 0.17\n",
            "It: 1410, Loss: 1.667e+02, l1: 0.784, l2: 0.00216, Time: 0.17\n",
            "It: 1420, Loss: 2.266e+02, l1: 0.786, l2: 0.00217, Time: 0.17\n",
            "It: 1430, Loss: 1.813e+02, l1: 0.788, l2: 0.00217, Time: 0.17\n",
            "It: 1440, Loss: 1.678e+02, l1: 0.790, l2: 0.00218, Time: 0.18\n",
            "It: 1450, Loss: 1.613e+02, l1: 0.792, l2: 0.00218, Time: 0.17\n",
            "It: 1460, Loss: 1.641e+02, l1: 0.794, l2: 0.00219, Time: 0.16\n",
            "It: 1470, Loss: 2.063e+02, l1: 0.796, l2: 0.00219, Time: 0.17\n",
            "It: 1480, Loss: 1.676e+02, l1: 0.797, l2: 0.00219, Time: 0.17\n",
            "It: 1490, Loss: 1.562e+02, l1: 0.799, l2: 0.00220, Time: 0.18\n",
            "It: 1500, Loss: 1.575e+02, l1: 0.801, l2: 0.00220, Time: 0.17\n",
            "It: 1510, Loss: 1.537e+02, l1: 0.802, l2: 0.00220, Time: 0.17\n",
            "It: 1520, Loss: 1.523e+02, l1: 0.804, l2: 0.00221, Time: 0.19\n",
            "It: 1530, Loss: 1.511e+02, l1: 0.806, l2: 0.00221, Time: 0.17\n",
            "It: 1540, Loss: 1.501e+02, l1: 0.808, l2: 0.00222, Time: 0.17\n",
            "It: 1550, Loss: 1.495e+02, l1: 0.810, l2: 0.00222, Time: 0.18\n",
            "It: 1560, Loss: 1.731e+02, l1: 0.811, l2: 0.00222, Time: 0.17\n",
            "It: 1570, Loss: 1.627e+02, l1: 0.813, l2: 0.00223, Time: 0.17\n",
            "It: 1580, Loss: 1.485e+02, l1: 0.814, l2: 0.00223, Time: 0.17\n",
            "It: 1590, Loss: 1.480e+02, l1: 0.816, l2: 0.00223, Time: 0.16\n",
            "It: 1600, Loss: 1.449e+02, l1: 0.818, l2: 0.00224, Time: 0.17\n",
            "It: 1610, Loss: 1.430e+02, l1: 0.819, l2: 0.00224, Time: 0.18\n",
            "It: 1620, Loss: 1.420e+02, l1: 0.821, l2: 0.00224, Time: 0.17\n",
            "It: 1630, Loss: 1.406e+02, l1: 0.822, l2: 0.00225, Time: 0.16\n",
            "It: 1640, Loss: 1.401e+02, l1: 0.824, l2: 0.00225, Time: 0.17\n",
            "It: 1650, Loss: 1.592e+02, l1: 0.826, l2: 0.00225, Time: 0.18\n",
            "It: 1660, Loss: 1.484e+02, l1: 0.827, l2: 0.00226, Time: 0.18\n",
            "It: 1670, Loss: 1.410e+02, l1: 0.828, l2: 0.00226, Time: 0.17\n",
            "It: 1680, Loss: 1.406e+02, l1: 0.830, l2: 0.00226, Time: 0.17\n",
            "It: 1690, Loss: 1.357e+02, l1: 0.831, l2: 0.00227, Time: 0.17\n",
            "It: 1700, Loss: 1.346e+02, l1: 0.833, l2: 0.00227, Time: 0.17\n",
            "It: 1710, Loss: 1.336e+02, l1: 0.834, l2: 0.00227, Time: 0.17\n",
            "It: 1720, Loss: 1.327e+02, l1: 0.836, l2: 0.00228, Time: 0.19\n",
            "It: 1730, Loss: 1.318e+02, l1: 0.837, l2: 0.00228, Time: 0.16\n",
            "It: 1740, Loss: 1.315e+02, l1: 0.839, l2: 0.00228, Time: 0.16\n",
            "It: 1750, Loss: 1.615e+02, l1: 0.840, l2: 0.00228, Time: 0.18\n",
            "It: 1760, Loss: 1.581e+02, l1: 0.841, l2: 0.00229, Time: 0.17\n",
            "It: 1770, Loss: 1.301e+02, l1: 0.842, l2: 0.00229, Time: 0.17\n",
            "It: 1780, Loss: 1.299e+02, l1: 0.844, l2: 0.00229, Time: 0.18\n",
            "It: 1790, Loss: 1.289e+02, l1: 0.845, l2: 0.00230, Time: 0.16\n",
            "It: 1800, Loss: 1.270e+02, l1: 0.846, l2: 0.00230, Time: 0.17\n",
            "It: 1810, Loss: 1.258e+02, l1: 0.848, l2: 0.00230, Time: 0.17\n",
            "It: 1820, Loss: 1.251e+02, l1: 0.849, l2: 0.00230, Time: 0.17\n",
            "It: 1830, Loss: 1.298e+02, l1: 0.850, l2: 0.00231, Time: 0.17\n",
            "It: 1840, Loss: 1.344e+02, l1: 0.852, l2: 0.00231, Time: 0.18\n",
            "It: 1850, Loss: 1.278e+02, l1: 0.853, l2: 0.00231, Time: 0.17\n",
            "It: 1860, Loss: 1.255e+02, l1: 0.854, l2: 0.00231, Time: 0.17\n",
            "It: 1870, Loss: 1.225e+02, l1: 0.855, l2: 0.00232, Time: 0.17\n",
            "It: 1880, Loss: 1.210e+02, l1: 0.857, l2: 0.00232, Time: 0.17\n",
            "It: 1890, Loss: 1.204e+02, l1: 0.858, l2: 0.00232, Time: 0.18\n",
            "It: 1900, Loss: 1.211e+02, l1: 0.859, l2: 0.00233, Time: 0.17\n",
            "It: 1910, Loss: 1.807e+02, l1: 0.861, l2: 0.00233, Time: 0.17\n",
            "It: 1920, Loss: 1.382e+02, l1: 0.862, l2: 0.00233, Time: 0.17\n",
            "It: 1930, Loss: 1.229e+02, l1: 0.863, l2: 0.00233, Time: 0.18\n",
            "It: 1940, Loss: 1.187e+02, l1: 0.864, l2: 0.00234, Time: 0.17\n",
            "It: 1950, Loss: 1.167e+02, l1: 0.865, l2: 0.00234, Time: 0.18\n",
            "It: 1960, Loss: 1.162e+02, l1: 0.866, l2: 0.00234, Time: 0.17\n",
            "It: 1970, Loss: 1.153e+02, l1: 0.867, l2: 0.00234, Time: 0.16\n",
            "It: 1980, Loss: 1.148e+02, l1: 0.868, l2: 0.00235, Time: 0.17\n",
            "It: 1990, Loss: 1.141e+02, l1: 0.870, l2: 0.00235, Time: 0.17\n",
            "It: 2000, Loss: 1.137e+02, l1: 0.871, l2: 0.00235, Time: 0.17\n",
            "It: 2010, Loss: 1.302e+02, l1: 0.872, l2: 0.00235, Time: 0.18\n",
            "It: 2020, Loss: 1.240e+02, l1: 0.873, l2: 0.00235, Time: 0.17\n",
            "It: 2030, Loss: 1.134e+02, l1: 0.874, l2: 0.00236, Time: 0.17\n",
            "It: 2040, Loss: 1.121e+02, l1: 0.875, l2: 0.00236, Time: 0.17\n",
            "It: 2050, Loss: 1.129e+02, l1: 0.876, l2: 0.00236, Time: 0.17\n",
            "It: 2060, Loss: 1.109e+02, l1: 0.877, l2: 0.00236, Time: 0.17\n",
            "It: 2070, Loss: 1.100e+02, l1: 0.878, l2: 0.00237, Time: 0.17\n",
            "It: 2080, Loss: 1.092e+02, l1: 0.879, l2: 0.00237, Time: 0.17\n",
            "It: 2090, Loss: 1.086e+02, l1: 0.880, l2: 0.00237, Time: 0.16\n",
            "It: 2100, Loss: 1.081e+02, l1: 0.881, l2: 0.00237, Time: 0.17\n",
            "It: 2110, Loss: 1.077e+02, l1: 0.882, l2: 0.00237, Time: 0.20\n",
            "It: 2120, Loss: 1.228e+02, l1: 0.883, l2: 0.00238, Time: 0.18\n",
            "It: 2130, Loss: 1.288e+02, l1: 0.884, l2: 0.00238, Time: 0.17\n",
            "It: 2140, Loss: 1.093e+02, l1: 0.885, l2: 0.00238, Time: 0.17\n",
            "It: 2150, Loss: 1.069e+02, l1: 0.886, l2: 0.00238, Time: 0.17\n",
            "It: 2160, Loss: 1.057e+02, l1: 0.887, l2: 0.00238, Time: 0.16\n",
            "It: 2170, Loss: 1.065e+02, l1: 0.888, l2: 0.00239, Time: 0.17\n",
            "It: 2180, Loss: 1.254e+02, l1: 0.889, l2: 0.00239, Time: 0.18\n",
            "It: 2190, Loss: 1.042e+02, l1: 0.890, l2: 0.00239, Time: 0.17\n",
            "It: 2200, Loss: 1.053e+02, l1: 0.891, l2: 0.00239, Time: 0.17\n",
            "It: 2210, Loss: 1.037e+02, l1: 0.892, l2: 0.00239, Time: 0.17\n",
            "It: 2220, Loss: 1.021e+02, l1: 0.893, l2: 0.00240, Time: 0.17\n",
            "It: 2230, Loss: 1.028e+02, l1: 0.894, l2: 0.00240, Time: 0.18\n",
            "It: 2240, Loss: 1.046e+02, l1: 0.895, l2: 0.00240, Time: 0.17\n",
            "It: 2250, Loss: 1.270e+02, l1: 0.896, l2: 0.00240, Time: 0.17\n",
            "It: 2260, Loss: 1.039e+02, l1: 0.897, l2: 0.00240, Time: 0.17\n",
            "It: 2270, Loss: 1.004e+02, l1: 0.898, l2: 0.00240, Time: 0.17\n",
            "It: 2280, Loss: 9.980e+01, l1: 0.899, l2: 0.00241, Time: 0.17\n",
            "It: 2290, Loss: 1.002e+02, l1: 0.900, l2: 0.00241, Time: 0.18\n",
            "It: 2300, Loss: 1.070e+02, l1: 0.900, l2: 0.00241, Time: 0.16\n",
            "It: 2310, Loss: 1.157e+02, l1: 0.901, l2: 0.00241, Time: 0.17\n",
            "It: 2320, Loss: 1.050e+02, l1: 0.902, l2: 0.00241, Time: 0.17\n",
            "It: 2330, Loss: 9.967e+01, l1: 0.903, l2: 0.00241, Time: 0.16\n",
            "It: 2340, Loss: 9.681e+01, l1: 0.904, l2: 0.00242, Time: 0.17\n",
            "It: 2350, Loss: 9.653e+01, l1: 0.905, l2: 0.00242, Time: 0.18\n",
            "It: 2360, Loss: 1.078e+02, l1: 0.906, l2: 0.00242, Time: 0.34\n",
            "It: 2370, Loss: 1.043e+02, l1: 0.906, l2: 0.00242, Time: 0.31\n",
            "It: 2380, Loss: 1.035e+02, l1: 0.907, l2: 0.00242, Time: 0.34\n",
            "It: 2390, Loss: 9.782e+01, l1: 0.908, l2: 0.00242, Time: 0.31\n",
            "It: 2400, Loss: 9.405e+01, l1: 0.909, l2: 0.00243, Time: 0.18\n",
            "It: 2410, Loss: 9.357e+01, l1: 0.909, l2: 0.00243, Time: 0.17\n",
            "It: 2420, Loss: 9.316e+01, l1: 0.910, l2: 0.00243, Time: 0.16\n",
            "It: 2430, Loss: 9.293e+01, l1: 0.911, l2: 0.00243, Time: 0.20\n",
            "It: 2440, Loss: 9.471e+01, l1: 0.912, l2: 0.00243, Time: 0.17\n",
            "It: 2450, Loss: 1.126e+02, l1: 0.913, l2: 0.00243, Time: 0.17\n",
            "It: 2460, Loss: 1.002e+02, l1: 0.914, l2: 0.00243, Time: 0.16\n",
            "It: 2470, Loss: 9.207e+01, l1: 0.914, l2: 0.00244, Time: 0.17\n",
            "It: 2480, Loss: 9.384e+01, l1: 0.915, l2: 0.00244, Time: 0.17\n",
            "It: 2490, Loss: 1.183e+02, l1: 0.916, l2: 0.00244, Time: 0.18\n",
            "It: 2500, Loss: 9.330e+01, l1: 0.917, l2: 0.00244, Time: 0.17\n",
            "It: 2510, Loss: 9.183e+01, l1: 0.917, l2: 0.00244, Time: 0.17\n",
            "It: 2520, Loss: 8.947e+01, l1: 0.918, l2: 0.00244, Time: 0.16\n",
            "It: 2530, Loss: 8.921e+01, l1: 0.919, l2: 0.00244, Time: 0.17\n",
            "It: 2540, Loss: 8.848e+01, l1: 0.920, l2: 0.00245, Time: 0.16\n",
            "It: 2550, Loss: 9.167e+01, l1: 0.920, l2: 0.00245, Time: 0.17\n",
            "It: 2560, Loss: 1.363e+02, l1: 0.921, l2: 0.00245, Time: 0.16\n",
            "It: 2570, Loss: 1.018e+02, l1: 0.922, l2: 0.00245, Time: 0.17\n",
            "It: 2580, Loss: 8.832e+01, l1: 0.922, l2: 0.00245, Time: 0.17\n",
            "It: 2590, Loss: 8.644e+01, l1: 0.923, l2: 0.00245, Time: 0.17\n",
            "It: 2600, Loss: 8.624e+01, l1: 0.924, l2: 0.00245, Time: 0.18\n",
            "It: 2610, Loss: 8.622e+01, l1: 0.925, l2: 0.00245, Time: 0.17\n",
            "It: 2620, Loss: 8.537e+01, l1: 0.925, l2: 0.00246, Time: 0.17\n",
            "It: 2630, Loss: 8.524e+01, l1: 0.926, l2: 0.00246, Time: 0.16\n",
            "It: 2640, Loss: 9.948e+01, l1: 0.927, l2: 0.00246, Time: 0.16\n",
            "It: 2650, Loss: 8.653e+01, l1: 0.927, l2: 0.00246, Time: 0.16\n",
            "It: 2660, Loss: 9.851e+01, l1: 0.928, l2: 0.00246, Time: 0.17\n",
            "It: 2670, Loss: 8.398e+01, l1: 0.928, l2: 0.00246, Time: 0.17\n",
            "It: 2680, Loss: 8.501e+01, l1: 0.929, l2: 0.00246, Time: 0.19\n",
            "It: 2690, Loss: 8.339e+01, l1: 0.930, l2: 0.00246, Time: 0.16\n",
            "It: 2700, Loss: 8.258e+01, l1: 0.930, l2: 0.00246, Time: 0.16\n",
            "It: 2710, Loss: 8.208e+01, l1: 0.931, l2: 0.00247, Time: 0.16\n",
            "It: 2720, Loss: 8.167e+01, l1: 0.932, l2: 0.00247, Time: 0.17\n",
            "It: 2730, Loss: 8.127e+01, l1: 0.933, l2: 0.00247, Time: 0.16\n",
            "It: 2740, Loss: 8.106e+01, l1: 0.933, l2: 0.00247, Time: 0.16\n",
            "It: 2750, Loss: 8.848e+01, l1: 0.934, l2: 0.00247, Time: 0.16\n",
            "It: 2760, Loss: 1.173e+02, l1: 0.934, l2: 0.00247, Time: 0.16\n",
            "It: 2770, Loss: 1.008e+02, l1: 0.935, l2: 0.00247, Time: 0.17\n",
            "It: 2780, Loss: 8.423e+01, l1: 0.935, l2: 0.00247, Time: 0.17\n",
            "It: 2790, Loss: 7.952e+01, l1: 0.936, l2: 0.00247, Time: 0.17\n",
            "It: 2800, Loss: 8.022e+01, l1: 0.936, l2: 0.00248, Time: 0.16\n",
            "It: 2810, Loss: 7.873e+01, l1: 0.937, l2: 0.00248, Time: 0.17\n",
            "It: 2820, Loss: 7.850e+01, l1: 0.938, l2: 0.00248, Time: 0.16\n",
            "It: 2830, Loss: 7.811e+01, l1: 0.938, l2: 0.00248, Time: 0.17\n",
            "It: 2840, Loss: 7.775e+01, l1: 0.939, l2: 0.00248, Time: 0.17\n",
            "It: 2850, Loss: 7.807e+01, l1: 0.940, l2: 0.00248, Time: 0.17\n",
            "It: 2860, Loss: 1.265e+02, l1: 0.940, l2: 0.00248, Time: 0.17\n",
            "It: 2870, Loss: 9.786e+01, l1: 0.941, l2: 0.00248, Time: 0.16\n",
            "It: 2880, Loss: 8.335e+01, l1: 0.941, l2: 0.00248, Time: 0.16\n",
            "It: 2890, Loss: 7.860e+01, l1: 0.942, l2: 0.00248, Time: 0.18\n",
            "It: 2900, Loss: 7.664e+01, l1: 0.942, l2: 0.00248, Time: 0.16\n",
            "It: 2910, Loss: 7.597e+01, l1: 0.943, l2: 0.00249, Time: 0.17\n",
            "It: 2920, Loss: 7.546e+01, l1: 0.944, l2: 0.00249, Time: 0.16\n",
            "It: 2930, Loss: 7.509e+01, l1: 0.944, l2: 0.00249, Time: 0.17\n",
            "It: 2940, Loss: 7.474e+01, l1: 0.945, l2: 0.00249, Time: 0.16\n",
            "It: 2950, Loss: 7.443e+01, l1: 0.945, l2: 0.00249, Time: 0.18\n",
            "It: 2960, Loss: 7.419e+01, l1: 0.946, l2: 0.00249, Time: 0.17\n",
            "It: 2970, Loss: 8.241e+01, l1: 0.947, l2: 0.00249, Time: 0.16\n",
            "It: 2980, Loss: 8.312e+01, l1: 0.947, l2: 0.00249, Time: 0.17\n",
            "It: 2990, Loss: 7.508e+01, l1: 0.947, l2: 0.00249, Time: 0.17\n",
            "It: 3000, Loss: 7.546e+01, l1: 0.947, l2: 0.00249, Time: 0.16\n",
            "It: 3010, Loss: 7.450e+01, l1: 0.948, l2: 0.00249, Time: 0.18\n",
            "It: 3020, Loss: 7.293e+01, l1: 0.948, l2: 0.00250, Time: 0.16\n",
            "It: 3030, Loss: 7.254e+01, l1: 0.949, l2: 0.00250, Time: 0.17\n",
            "It: 3040, Loss: 7.238e+01, l1: 0.949, l2: 0.00250, Time: 0.16\n",
            "It: 3050, Loss: 7.188e+01, l1: 0.950, l2: 0.00250, Time: 0.17\n",
            "It: 3060, Loss: 7.162e+01, l1: 0.950, l2: 0.00250, Time: 0.17\n",
            "It: 3070, Loss: 7.132e+01, l1: 0.951, l2: 0.00250, Time: 0.18\n",
            "It: 3080, Loss: 7.105e+01, l1: 0.952, l2: 0.00250, Time: 0.17\n",
            "It: 3090, Loss: 7.078e+01, l1: 0.952, l2: 0.00250, Time: 0.17\n",
            "It: 3100, Loss: 7.052e+01, l1: 0.953, l2: 0.00250, Time: 0.16\n",
            "It: 3110, Loss: 7.025e+01, l1: 0.953, l2: 0.00250, Time: 0.17\n",
            "It: 3120, Loss: 6.999e+01, l1: 0.954, l2: 0.00250, Time: 0.17\n",
            "It: 3130, Loss: 6.972e+01, l1: 0.954, l2: 0.00250, Time: 0.18\n",
            "It: 3140, Loss: 6.947e+01, l1: 0.955, l2: 0.00250, Time: 0.16\n",
            "It: 3150, Loss: 6.932e+01, l1: 0.955, l2: 0.00251, Time: 0.17\n",
            "It: 3160, Loss: 8.419e+01, l1: 0.956, l2: 0.00251, Time: 0.17\n",
            "It: 3170, Loss: 8.492e+01, l1: 0.956, l2: 0.00251, Time: 0.17\n",
            "It: 3180, Loss: 7.277e+01, l1: 0.956, l2: 0.00251, Time: 0.18\n",
            "It: 3190, Loss: 7.209e+01, l1: 0.957, l2: 0.00251, Time: 0.17\n",
            "It: 3200, Loss: 6.979e+01, l1: 0.957, l2: 0.00251, Time: 0.16\n",
            "It: 3210, Loss: 6.822e+01, l1: 0.957, l2: 0.00251, Time: 0.16\n",
            "It: 3220, Loss: 6.773e+01, l1: 0.958, l2: 0.00251, Time: 0.16\n",
            "It: 3230, Loss: 6.757e+01, l1: 0.958, l2: 0.00251, Time: 0.16\n",
            "It: 3240, Loss: 6.724e+01, l1: 0.959, l2: 0.00251, Time: 0.17\n",
            "It: 3250, Loss: 6.698e+01, l1: 0.959, l2: 0.00251, Time: 0.17\n",
            "It: 3260, Loss: 6.678e+01, l1: 0.960, l2: 0.00251, Time: 0.18\n",
            "It: 3270, Loss: 6.980e+01, l1: 0.960, l2: 0.00252, Time: 0.17\n",
            "It: 3280, Loss: 1.179e+02, l1: 0.961, l2: 0.00252, Time: 0.16\n",
            "It: 3290, Loss: 6.884e+01, l1: 0.961, l2: 0.00252, Time: 0.16\n",
            "It: 3300, Loss: 7.259e+01, l1: 0.961, l2: 0.00252, Time: 0.17\n",
            "It: 3310, Loss: 6.604e+01, l1: 0.962, l2: 0.00252, Time: 0.16\n",
            "It: 3320, Loss: 6.582e+01, l1: 0.962, l2: 0.00252, Time: 0.16\n",
            "It: 3330, Loss: 6.556e+01, l1: 0.963, l2: 0.00252, Time: 0.16\n",
            "It: 3340, Loss: 6.513e+01, l1: 0.963, l2: 0.00252, Time: 0.16\n",
            "It: 3350, Loss: 6.484e+01, l1: 0.964, l2: 0.00252, Time: 0.16\n",
            "It: 3360, Loss: 6.465e+01, l1: 0.964, l2: 0.00252, Time: 0.18\n",
            "It: 3370, Loss: 6.441e+01, l1: 0.965, l2: 0.00252, Time: 0.16\n",
            "It: 3380, Loss: 6.421e+01, l1: 0.965, l2: 0.00252, Time: 0.15\n",
            "It: 3390, Loss: 6.452e+01, l1: 0.966, l2: 0.00252, Time: 0.16\n",
            "It: 3400, Loss: 1.095e+02, l1: 0.966, l2: 0.00252, Time: 0.16\n",
            "It: 3410, Loss: 1.077e+02, l1: 0.966, l2: 0.00253, Time: 0.17\n",
            "It: 3420, Loss: 7.189e+01, l1: 0.966, l2: 0.00253, Time: 0.17\n",
            "It: 3430, Loss: 6.389e+01, l1: 0.966, l2: 0.00253, Time: 0.16\n",
            "It: 3440, Loss: 6.444e+01, l1: 0.967, l2: 0.00253, Time: 0.16\n",
            "It: 3450, Loss: 6.352e+01, l1: 0.967, l2: 0.00253, Time: 0.16\n",
            "It: 3460, Loss: 6.295e+01, l1: 0.968, l2: 0.00253, Time: 0.16\n",
            "It: 3470, Loss: 6.260e+01, l1: 0.968, l2: 0.00253, Time: 0.16\n",
            "It: 3480, Loss: 6.240e+01, l1: 0.968, l2: 0.00253, Time: 0.18\n",
            "It: 3490, Loss: 6.219e+01, l1: 0.969, l2: 0.00253, Time: 0.16\n",
            "It: 3500, Loss: 6.199e+01, l1: 0.969, l2: 0.00253, Time: 0.16\n",
            "It: 3510, Loss: 6.180e+01, l1: 0.970, l2: 0.00253, Time: 0.16\n",
            "It: 3520, Loss: 6.161e+01, l1: 0.970, l2: 0.00253, Time: 0.16\n",
            "It: 3530, Loss: 6.142e+01, l1: 0.971, l2: 0.00253, Time: 0.17\n",
            "It: 3540, Loss: 6.127e+01, l1: 0.971, l2: 0.00253, Time: 0.17\n",
            "It: 3550, Loss: 6.495e+01, l1: 0.971, l2: 0.00253, Time: 0.17\n",
            "It: 3560, Loss: 1.342e+02, l1: 0.972, l2: 0.00254, Time: 0.16\n",
            "It: 3570, Loss: 8.451e+01, l1: 0.972, l2: 0.00254, Time: 0.17\n",
            "It: 3580, Loss: 6.661e+01, l1: 0.972, l2: 0.00254, Time: 0.18\n",
            "It: 3590, Loss: 6.143e+01, l1: 0.972, l2: 0.00254, Time: 0.17\n",
            "It: 3600, Loss: 6.053e+01, l1: 0.973, l2: 0.00254, Time: 0.17\n",
            "It: 3610, Loss: 6.028e+01, l1: 0.973, l2: 0.00254, Time: 0.17\n",
            "It: 3620, Loss: 6.011e+01, l1: 0.973, l2: 0.00254, Time: 0.16\n",
            "It: 3630, Loss: 5.989e+01, l1: 0.974, l2: 0.00254, Time: 0.16\n",
            "It: 3640, Loss: 5.967e+01, l1: 0.974, l2: 0.00254, Time: 0.16\n",
            "It: 3650, Loss: 5.950e+01, l1: 0.975, l2: 0.00254, Time: 0.16\n",
            "It: 3660, Loss: 5.974e+01, l1: 0.975, l2: 0.00254, Time: 0.16\n",
            "It: 3670, Loss: 8.809e+01, l1: 0.975, l2: 0.00254, Time: 0.16\n",
            "It: 3680, Loss: 7.534e+01, l1: 0.976, l2: 0.00254, Time: 0.16\n",
            "It: 3690, Loss: 6.113e+01, l1: 0.976, l2: 0.00254, Time: 0.16\n",
            "It: 3700, Loss: 6.428e+01, l1: 0.976, l2: 0.00254, Time: 0.16\n",
            "It: 3710, Loss: 5.895e+01, l1: 0.976, l2: 0.00254, Time: 0.17\n",
            "It: 3720, Loss: 5.936e+01, l1: 0.976, l2: 0.00254, Time: 0.17\n",
            "It: 3730, Loss: 5.849e+01, l1: 0.977, l2: 0.00255, Time: 0.16\n",
            "It: 3740, Loss: 5.819e+01, l1: 0.977, l2: 0.00255, Time: 0.17\n",
            "It: 3750, Loss: 5.802e+01, l1: 0.978, l2: 0.00255, Time: 0.16\n",
            "It: 3760, Loss: 5.787e+01, l1: 0.978, l2: 0.00255, Time: 0.16\n",
            "It: 3770, Loss: 5.770e+01, l1: 0.978, l2: 0.00255, Time: 0.17\n",
            "It: 3780, Loss: 5.754e+01, l1: 0.979, l2: 0.00255, Time: 0.17\n",
            "It: 3790, Loss: 5.739e+01, l1: 0.979, l2: 0.00255, Time: 0.16\n",
            "It: 3800, Loss: 5.731e+01, l1: 0.979, l2: 0.00255, Time: 0.15\n",
            "It: 3810, Loss: 6.213e+01, l1: 0.980, l2: 0.00255, Time: 0.16\n",
            "It: 3820, Loss: 1.371e+02, l1: 0.980, l2: 0.00255, Time: 0.17\n",
            "It: 3830, Loss: 7.352e+01, l1: 0.980, l2: 0.00255, Time: 0.17\n",
            "It: 3840, Loss: 5.795e+01, l1: 0.980, l2: 0.00255, Time: 0.18\n",
            "It: 3850, Loss: 5.795e+01, l1: 0.980, l2: 0.00255, Time: 0.16\n",
            "It: 3860, Loss: 5.763e+01, l1: 0.981, l2: 0.00255, Time: 0.16\n",
            "It: 3870, Loss: 5.654e+01, l1: 0.981, l2: 0.00255, Time: 0.17\n",
            "It: 3880, Loss: 5.624e+01, l1: 0.981, l2: 0.00255, Time: 0.17\n",
            "It: 3890, Loss: 5.606e+01, l1: 0.981, l2: 0.00255, Time: 0.17\n",
            "It: 3900, Loss: 5.588e+01, l1: 0.982, l2: 0.00255, Time: 0.16\n",
            "It: 3910, Loss: 5.572e+01, l1: 0.982, l2: 0.00255, Time: 0.16\n",
            "It: 3920, Loss: 5.557e+01, l1: 0.983, l2: 0.00256, Time: 0.16\n",
            "It: 3930, Loss: 5.541e+01, l1: 0.983, l2: 0.00256, Time: 0.17\n",
            "It: 3940, Loss: 5.526e+01, l1: 0.983, l2: 0.00256, Time: 0.16\n",
            "It: 3950, Loss: 5.511e+01, l1: 0.984, l2: 0.00256, Time: 0.17\n",
            "It: 3960, Loss: 5.503e+01, l1: 0.984, l2: 0.00256, Time: 0.16\n",
            "It: 3970, Loss: 6.241e+01, l1: 0.984, l2: 0.00256, Time: 0.16\n",
            "It: 3980, Loss: 8.550e+01, l1: 0.984, l2: 0.00256, Time: 0.16\n",
            "It: 3990, Loss: 5.796e+01, l1: 0.984, l2: 0.00256, Time: 0.16\n",
            "It: 4000, Loss: 5.557e+01, l1: 0.984, l2: 0.00256, Time: 0.17\n",
            "It: 4010, Loss: 5.539e+01, l1: 0.985, l2: 0.00256, Time: 0.18\n",
            "It: 4020, Loss: 5.487e+01, l1: 0.985, l2: 0.00256, Time: 0.16\n",
            "It: 4030, Loss: 5.431e+01, l1: 0.985, l2: 0.00256, Time: 0.16\n",
            "It: 4040, Loss: 5.397e+01, l1: 0.985, l2: 0.00256, Time: 0.16\n",
            "It: 4050, Loss: 5.379e+01, l1: 0.986, l2: 0.00256, Time: 0.17\n",
            "It: 4060, Loss: 5.365e+01, l1: 0.986, l2: 0.00256, Time: 0.16\n",
            "It: 4070, Loss: 5.350e+01, l1: 0.986, l2: 0.00256, Time: 0.18\n",
            "It: 4080, Loss: 5.339e+01, l1: 0.987, l2: 0.00256, Time: 0.17\n",
            "It: 4090, Loss: 5.485e+01, l1: 0.987, l2: 0.00256, Time: 0.16\n",
            "It: 4100, Loss: 1.345e+02, l1: 0.987, l2: 0.00256, Time: 0.17\n",
            "It: 4110, Loss: 7.095e+01, l1: 0.987, l2: 0.00256, Time: 0.17\n",
            "It: 4120, Loss: 6.311e+01, l1: 0.987, l2: 0.00256, Time: 0.16\n",
            "It: 4130, Loss: 5.294e+01, l1: 0.987, l2: 0.00256, Time: 0.18\n",
            "It: 4140, Loss: 5.421e+01, l1: 0.988, l2: 0.00257, Time: 0.16\n",
            "It: 4150, Loss: 5.256e+01, l1: 0.988, l2: 0.00257, Time: 0.17\n",
            "It: 4160, Loss: 5.233e+01, l1: 0.988, l2: 0.00257, Time: 0.16\n",
            "It: 4170, Loss: 5.218e+01, l1: 0.988, l2: 0.00257, Time: 0.17\n",
            "It: 4180, Loss: 5.202e+01, l1: 0.989, l2: 0.00257, Time: 0.17\n",
            "It: 4190, Loss: 5.187e+01, l1: 0.989, l2: 0.00257, Time: 0.18\n",
            "It: 4200, Loss: 5.173e+01, l1: 0.989, l2: 0.00257, Time: 0.16\n",
            "It: 4210, Loss: 5.157e+01, l1: 0.990, l2: 0.00257, Time: 0.17\n",
            "It: 4220, Loss: 5.143e+01, l1: 0.990, l2: 0.00257, Time: 0.18\n",
            "It: 4230, Loss: 5.129e+01, l1: 0.990, l2: 0.00257, Time: 0.16\n",
            "It: 4240, Loss: 5.223e+01, l1: 0.990, l2: 0.00257, Time: 0.17\n",
            "It: 4250, Loss: 1.501e+02, l1: 0.991, l2: 0.00257, Time: 0.16\n",
            "It: 4260, Loss: 6.393e+01, l1: 0.990, l2: 0.00257, Time: 0.15\n",
            "It: 4270, Loss: 5.852e+01, l1: 0.990, l2: 0.00257, Time: 0.17\n",
            "It: 4280, Loss: 5.544e+01, l1: 0.991, l2: 0.00257, Time: 0.16\n",
            "It: 4290, Loss: 5.239e+01, l1: 0.991, l2: 0.00257, Time: 0.16\n",
            "It: 4300, Loss: 5.048e+01, l1: 0.991, l2: 0.00257, Time: 0.18\n",
            "It: 4310, Loss: 5.056e+01, l1: 0.991, l2: 0.00257, Time: 0.17\n",
            "It: 4320, Loss: 5.013e+01, l1: 0.991, l2: 0.00257, Time: 0.17\n",
            "It: 4330, Loss: 4.998e+01, l1: 0.992, l2: 0.00257, Time: 0.16\n",
            "It: 4340, Loss: 4.983e+01, l1: 0.992, l2: 0.00257, Time: 0.17\n",
            "It: 4350, Loss: 4.968e+01, l1: 0.992, l2: 0.00257, Time: 0.18\n",
            "It: 4360, Loss: 4.953e+01, l1: 0.993, l2: 0.00257, Time: 0.17\n",
            "It: 4370, Loss: 4.938e+01, l1: 0.993, l2: 0.00257, Time: 0.16\n",
            "It: 4380, Loss: 4.923e+01, l1: 0.993, l2: 0.00257, Time: 0.16\n",
            "It: 4390, Loss: 4.908e+01, l1: 0.993, l2: 0.00257, Time: 0.17\n",
            "It: 4400, Loss: 4.894e+01, l1: 0.994, l2: 0.00257, Time: 0.17\n",
            "It: 4410, Loss: 4.894e+01, l1: 0.994, l2: 0.00257, Time: 0.17\n",
            "It: 4420, Loss: 6.783e+01, l1: 0.994, l2: 0.00257, Time: 0.17\n",
            "It: 4430, Loss: 8.934e+01, l1: 0.994, l2: 0.00258, Time: 0.17\n",
            "It: 4440, Loss: 5.937e+01, l1: 0.994, l2: 0.00258, Time: 0.16\n",
            "It: 4450, Loss: 5.365e+01, l1: 0.994, l2: 0.00258, Time: 0.17\n",
            "It: 4460, Loss: 5.019e+01, l1: 0.994, l2: 0.00258, Time: 0.16\n",
            "It: 4470, Loss: 4.864e+01, l1: 0.995, l2: 0.00258, Time: 0.18\n",
            "It: 4480, Loss: 4.820e+01, l1: 0.995, l2: 0.00258, Time: 0.17\n",
            "It: 4490, Loss: 4.781e+01, l1: 0.995, l2: 0.00258, Time: 0.16\n",
            "It: 4500, Loss: 4.765e+01, l1: 0.995, l2: 0.00258, Time: 0.16\n",
            "It: 4510, Loss: 4.853e+01, l1: 0.996, l2: 0.00258, Time: 0.16\n",
            "It: 4520, Loss: 9.505e+01, l1: 0.996, l2: 0.00258, Time: 0.16\n",
            "It: 4530, Loss: 7.537e+01, l1: 0.996, l2: 0.00258, Time: 0.16\n",
            "It: 4540, Loss: 4.756e+01, l1: 0.996, l2: 0.00258, Time: 0.17\n",
            "It: 4550, Loss: 5.141e+01, l1: 0.996, l2: 0.00258, Time: 0.16\n",
            "It: 4560, Loss: 4.715e+01, l1: 0.996, l2: 0.00258, Time: 0.16\n",
            "It: 4570, Loss: 4.674e+01, l1: 0.996, l2: 0.00258, Time: 0.17\n",
            "It: 4580, Loss: 4.660e+01, l1: 0.996, l2: 0.00258, Time: 0.16\n",
            "It: 4590, Loss: 4.639e+01, l1: 0.997, l2: 0.00258, Time: 0.17\n",
            "It: 4600, Loss: 4.623e+01, l1: 0.997, l2: 0.00258, Time: 0.17\n",
            "It: 4610, Loss: 4.610e+01, l1: 0.997, l2: 0.00258, Time: 0.16\n",
            "It: 4620, Loss: 4.593e+01, l1: 0.997, l2: 0.00258, Time: 0.16\n",
            "It: 4630, Loss: 4.578e+01, l1: 0.998, l2: 0.00258, Time: 0.16\n",
            "It: 4640, Loss: 4.563e+01, l1: 0.998, l2: 0.00258, Time: 0.16\n",
            "It: 4650, Loss: 4.581e+01, l1: 0.998, l2: 0.00258, Time: 0.17\n",
            "It: 4660, Loss: 8.681e+01, l1: 0.998, l2: 0.00258, Time: 0.16\n",
            "It: 4670, Loss: 9.897e+01, l1: 0.998, l2: 0.00258, Time: 0.17\n",
            "It: 4680, Loss: 6.220e+01, l1: 0.998, l2: 0.00258, Time: 0.16\n",
            "It: 4690, Loss: 5.060e+01, l1: 0.998, l2: 0.00258, Time: 0.17\n",
            "It: 4700, Loss: 4.559e+01, l1: 0.998, l2: 0.00258, Time: 0.16\n",
            "It: 4710, Loss: 4.500e+01, l1: 0.998, l2: 0.00258, Time: 0.17\n",
            "It: 4720, Loss: 4.496e+01, l1: 0.998, l2: 0.00258, Time: 0.16\n",
            "It: 4730, Loss: 4.444e+01, l1: 0.998, l2: 0.00258, Time: 0.17\n",
            "It: 4740, Loss: 4.430e+01, l1: 0.999, l2: 0.00258, Time: 0.16\n",
            "It: 4750, Loss: 4.412e+01, l1: 0.999, l2: 0.00258, Time: 0.16\n",
            "It: 4760, Loss: 4.395e+01, l1: 0.999, l2: 0.00258, Time: 0.16\n",
            "It: 4770, Loss: 4.379e+01, l1: 0.999, l2: 0.00258, Time: 0.16\n",
            "It: 4780, Loss: 4.363e+01, l1: 1.000, l2: 0.00258, Time: 0.16\n",
            "It: 4790, Loss: 4.347e+01, l1: 1.000, l2: 0.00258, Time: 0.17\n",
            "It: 4800, Loss: 4.331e+01, l1: 1.000, l2: 0.00258, Time: 0.16\n",
            "It: 4810, Loss: 4.315e+01, l1: 1.000, l2: 0.00258, Time: 0.16\n",
            "It: 4820, Loss: 4.299e+01, l1: 1.000, l2: 0.00258, Time: 0.16\n",
            "It: 4830, Loss: 4.283e+01, l1: 1.001, l2: 0.00258, Time: 0.16\n",
            "It: 4840, Loss: 4.303e+01, l1: 1.001, l2: 0.00258, Time: 0.16\n",
            "It: 4850, Loss: 9.240e+01, l1: 1.001, l2: 0.00258, Time: 0.16\n",
            "It: 4860, Loss: 9.847e+01, l1: 1.001, l2: 0.00259, Time: 0.16\n",
            "It: 4870, Loss: 6.221e+01, l1: 1.001, l2: 0.00259, Time: 0.16\n",
            "It: 4880, Loss: 4.952e+01, l1: 1.001, l2: 0.00259, Time: 0.16\n",
            "It: 4890, Loss: 4.410e+01, l1: 1.001, l2: 0.00259, Time: 0.16\n",
            "It: 4900, Loss: 4.190e+01, l1: 1.001, l2: 0.00259, Time: 0.17\n",
            "It: 4910, Loss: 4.194e+01, l1: 1.001, l2: 0.00259, Time: 0.16\n",
            "It: 4920, Loss: 4.152e+01, l1: 1.001, l2: 0.00259, Time: 0.17\n",
            "It: 4930, Loss: 4.134e+01, l1: 1.001, l2: 0.00259, Time: 0.16\n",
            "It: 4940, Loss: 4.111e+01, l1: 1.002, l2: 0.00259, Time: 0.16\n",
            "It: 4950, Loss: 4.094e+01, l1: 1.002, l2: 0.00259, Time: 0.16\n",
            "It: 4960, Loss: 4.081e+01, l1: 1.002, l2: 0.00259, Time: 0.17\n",
            "It: 4970, Loss: 4.587e+01, l1: 1.002, l2: 0.00259, Time: 0.17\n",
            "It: 4980, Loss: 4.276e+01, l1: 1.002, l2: 0.00259, Time: 0.16\n",
            "It: 4990, Loss: 4.790e+01, l1: 1.002, l2: 0.00259, Time: 0.16\n",
            "It: 5000, Loss: 4.340e+01, l1: 1.002, l2: 0.00259, Time: 0.16\n",
            "It: 5010, Loss: 4.035e+01, l1: 1.003, l2: 0.00259, Time: 0.16\n",
            "It: 5020, Loss: 3.979e+01, l1: 1.003, l2: 0.00259, Time: 0.17\n",
            "It: 5030, Loss: 3.974e+01, l1: 1.003, l2: 0.00259, Time: 0.17\n",
            "It: 5040, Loss: 3.937e+01, l1: 1.003, l2: 0.00259, Time: 0.16\n",
            "It: 5050, Loss: 3.920e+01, l1: 1.003, l2: 0.00259, Time: 0.16\n",
            "It: 5060, Loss: 3.900e+01, l1: 1.004, l2: 0.00259, Time: 0.16\n",
            "It: 5070, Loss: 3.958e+01, l1: 1.004, l2: 0.00259, Time: 0.19\n",
            "It: 5080, Loss: 1.083e+02, l1: 1.004, l2: 0.00259, Time: 0.16\n",
            "It: 5090, Loss: 7.620e+01, l1: 1.004, l2: 0.00259, Time: 0.17\n",
            "It: 5100, Loss: 5.334e+01, l1: 1.003, l2: 0.00259, Time: 0.16\n",
            "It: 5110, Loss: 4.165e+01, l1: 1.003, l2: 0.00259, Time: 0.16\n",
            "It: 5120, Loss: 3.815e+01, l1: 1.004, l2: 0.00259, Time: 0.15\n",
            "It: 5130, Loss: 3.859e+01, l1: 1.004, l2: 0.00259, Time: 0.15\n",
            "It: 5140, Loss: 3.763e+01, l1: 1.004, l2: 0.00259, Time: 0.16\n",
            "It: 5150, Loss: 3.743e+01, l1: 1.004, l2: 0.00259, Time: 0.16\n",
            "It: 5160, Loss: 3.722e+01, l1: 1.004, l2: 0.00259, Time: 0.16\n",
            "It: 5170, Loss: 3.700e+01, l1: 1.004, l2: 0.00259, Time: 0.16\n",
            "It: 5180, Loss: 3.678e+01, l1: 1.005, l2: 0.00259, Time: 0.15\n",
            "It: 5190, Loss: 3.657e+01, l1: 1.005, l2: 0.00259, Time: 0.16\n",
            "It: 5200, Loss: 3.636e+01, l1: 1.005, l2: 0.00259, Time: 0.17\n",
            "It: 5210, Loss: 3.615e+01, l1: 1.005, l2: 0.00259, Time: 0.17\n",
            "It: 5220, Loss: 3.594e+01, l1: 1.005, l2: 0.00259, Time: 0.16\n",
            "It: 5230, Loss: 3.575e+01, l1: 1.005, l2: 0.00259, Time: 0.16\n",
            "It: 5240, Loss: 3.692e+01, l1: 1.006, l2: 0.00259, Time: 0.15\n",
            "It: 5250, Loss: 1.388e+02, l1: 1.006, l2: 0.00259, Time: 0.16\n",
            "It: 5260, Loss: 4.209e+01, l1: 1.005, l2: 0.00259, Time: 0.17\n",
            "It: 5270, Loss: 3.841e+01, l1: 1.005, l2: 0.00259, Time: 0.18\n",
            "It: 5280, Loss: 3.737e+01, l1: 1.005, l2: 0.00259, Time: 0.15\n",
            "It: 5290, Loss: 3.634e+01, l1: 1.005, l2: 0.00259, Time: 0.17\n",
            "It: 5300, Loss: 3.478e+01, l1: 1.006, l2: 0.00259, Time: 0.15\n",
            "It: 5310, Loss: 3.421e+01, l1: 1.006, l2: 0.00259, Time: 0.16\n",
            "It: 5320, Loss: 3.405e+01, l1: 1.006, l2: 0.00259, Time: 0.17\n",
            "It: 5330, Loss: 3.375e+01, l1: 1.006, l2: 0.00259, Time: 0.17\n",
            "It: 5340, Loss: 3.353e+01, l1: 1.006, l2: 0.00259, Time: 0.16\n",
            "It: 5350, Loss: 3.331e+01, l1: 1.006, l2: 0.00259, Time: 0.16\n",
            "It: 5360, Loss: 3.310e+01, l1: 1.006, l2: 0.00259, Time: 0.16\n",
            "It: 5370, Loss: 3.343e+01, l1: 1.007, l2: 0.00259, Time: 0.17\n",
            "It: 5380, Loss: 7.746e+01, l1: 1.007, l2: 0.00259, Time: 0.18\n",
            "It: 5390, Loss: 5.939e+01, l1: 1.007, l2: 0.00259, Time: 0.16\n",
            "It: 5400, Loss: 3.961e+01, l1: 1.007, l2: 0.00259, Time: 0.16\n",
            "It: 5410, Loss: 3.360e+01, l1: 1.007, l2: 0.00259, Time: 0.16\n",
            "It: 5420, Loss: 3.255e+01, l1: 1.007, l2: 0.00259, Time: 0.16\n",
            "It: 5430, Loss: 3.224e+01, l1: 1.007, l2: 0.00259, Time: 0.16\n",
            "It: 5440, Loss: 3.156e+01, l1: 1.007, l2: 0.00259, Time: 0.17\n",
            "It: 5450, Loss: 3.128e+01, l1: 1.007, l2: 0.00259, Time: 0.17\n",
            "It: 5460, Loss: 3.100e+01, l1: 1.007, l2: 0.00259, Time: 0.16\n",
            "It: 5470, Loss: 3.078e+01, l1: 1.007, l2: 0.00259, Time: 0.17\n",
            "It: 5480, Loss: 3.059e+01, l1: 1.008, l2: 0.00259, Time: 0.17\n",
            "It: 5490, Loss: 3.108e+01, l1: 1.008, l2: 0.00259, Time: 0.17\n",
            "It: 5500, Loss: 6.991e+01, l1: 1.008, l2: 0.00259, Time: 0.16\n",
            "It: 5510, Loss: 5.596e+01, l1: 1.008, l2: 0.00259, Time: 0.17\n",
            "It: 5520, Loss: 3.071e+01, l1: 1.008, l2: 0.00259, Time: 0.15\n",
            "It: 5530, Loss: 3.430e+01, l1: 1.008, l2: 0.00259, Time: 0.16\n",
            "It: 5540, Loss: 2.972e+01, l1: 1.008, l2: 0.00259, Time: 0.16\n",
            "It: 5550, Loss: 2.959e+01, l1: 1.008, l2: 0.00259, Time: 0.20\n",
            "It: 5560, Loss: 2.915e+01, l1: 1.008, l2: 0.00259, Time: 0.16\n",
            "It: 5570, Loss: 2.883e+01, l1: 1.008, l2: 0.00259, Time: 0.17\n",
            "It: 5580, Loss: 2.857e+01, l1: 1.008, l2: 0.00259, Time: 0.16\n",
            "It: 5590, Loss: 2.833e+01, l1: 1.008, l2: 0.00259, Time: 0.17\n",
            "It: 5600, Loss: 2.813e+01, l1: 1.008, l2: 0.00259, Time: 0.17\n",
            "It: 5610, Loss: 2.792e+01, l1: 1.009, l2: 0.00259, Time: 0.17\n",
            "It: 5620, Loss: 2.774e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5630, Loss: 2.853e+01, l1: 1.009, l2: 0.00259, Time: 0.17\n",
            "It: 5640, Loss: 8.642e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5650, Loss: 5.972e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5660, Loss: 3.256e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5670, Loss: 2.763e+01, l1: 1.009, l2: 0.00259, Time: 0.19\n",
            "It: 5680, Loss: 2.824e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5690, Loss: 2.669e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5700, Loss: 2.626e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5710, Loss: 2.608e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5720, Loss: 2.589e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5730, Loss: 2.653e+01, l1: 1.009, l2: 0.00259, Time: 0.17\n",
            "It: 5740, Loss: 6.270e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5750, Loss: 3.454e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5760, Loss: 2.829e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5770, Loss: 2.570e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5780, Loss: 2.516e+01, l1: 1.009, l2: 0.00259, Time: 0.16\n",
            "It: 5790, Loss: 2.495e+01, l1: 1.010, l2: 0.00259, Time: 0.18\n",
            "It: 5800, Loss: 2.453e+01, l1: 1.010, l2: 0.00259, Time: 0.16\n",
            "It: 5810, Loss: 2.452e+01, l1: 1.010, l2: 0.00259, Time: 0.16\n",
            "It: 5820, Loss: 2.943e+01, l1: 1.010, l2: 0.00258, Time: 0.15\n",
            "It: 5830, Loss: 8.180e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 5840, Loss: 2.607e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 5850, Loss: 2.850e+01, l1: 1.010, l2: 0.00258, Time: 0.18\n",
            "It: 5860, Loss: 2.568e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 5870, Loss: 2.372e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 5880, Loss: 2.334e+01, l1: 1.010, l2: 0.00258, Time: 0.15\n",
            "It: 5890, Loss: 2.318e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 5900, Loss: 2.295e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 5910, Loss: 2.274e+01, l1: 1.010, l2: 0.00258, Time: 0.18\n",
            "It: 5920, Loss: 2.257e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 5930, Loss: 2.242e+01, l1: 1.010, l2: 0.00258, Time: 0.18\n",
            "It: 5940, Loss: 2.235e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 5950, Loss: 3.146e+01, l1: 1.010, l2: 0.00258, Time: 0.18\n",
            "It: 5960, Loss: 3.834e+01, l1: 1.010, l2: 0.00258, Time: 0.18\n",
            "It: 5970, Loss: 3.776e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 5980, Loss: 2.924e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 5990, Loss: 2.538e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6000, Loss: 2.214e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6010, Loss: 2.159e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6020, Loss: 2.140e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 6030, Loss: 2.117e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6040, Loss: 2.099e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6050, Loss: 2.086e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6060, Loss: 2.073e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6070, Loss: 2.077e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6080, Loss: 3.625e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6090, Loss: 3.251e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 6100, Loss: 2.067e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6110, Loss: 2.234e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6120, Loss: 2.054e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 6130, Loss: 1.998e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 6140, Loss: 1.988e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 6150, Loss: 1.969e+01, l1: 1.011, l2: 0.00258, Time: 0.17\n",
            "It: 6160, Loss: 1.979e+01, l1: 1.011, l2: 0.00258, Time: 0.16\n",
            "It: 6170, Loss: 3.251e+01, l1: 1.011, l2: 0.00258, Time: 0.17\n",
            "It: 6180, Loss: 2.569e+01, l1: 1.011, l2: 0.00258, Time: 0.17\n",
            "It: 6190, Loss: 3.645e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6200, Loss: 2.008e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 6210, Loss: 2.131e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6220, Loss: 1.900e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6230, Loss: 1.900e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6240, Loss: 1.885e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6250, Loss: 1.868e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 6260, Loss: 1.854e+01, l1: 1.010, l2: 0.00258, Time: 0.17\n",
            "It: 6270, Loss: 1.844e+01, l1: 1.010, l2: 0.00258, Time: 0.16\n",
            "It: 6280, Loss: 1.833e+01, l1: 1.010, l2: 0.00258, Time: 0.15\n",
            "It: 6290, Loss: 1.824e+01, l1: 1.011, l2: 0.00258, Time: 0.16\n",
            "It: 6300, Loss: 1.820e+01, l1: 1.011, l2: 0.00257, Time: 0.16\n",
            "It: 6310, Loss: 2.041e+01, l1: 1.011, l2: 0.00257, Time: 0.17\n",
            "It: 6320, Loss: 9.721e+01, l1: 1.011, l2: 0.00257, Time: 0.17\n",
            "It: 6330, Loss: 3.037e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6340, Loss: 2.556e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6350, Loss: 1.825e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6360, Loss: 1.845e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6370, Loss: 1.809e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6380, Loss: 1.761e+01, l1: 1.010, l2: 0.00257, Time: 0.17\n",
            "It: 6390, Loss: 1.742e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6400, Loss: 1.729e+01, l1: 1.010, l2: 0.00257, Time: 0.15\n",
            "It: 6410, Loss: 1.717e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6420, Loss: 1.741e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6430, Loss: 3.991e+01, l1: 1.010, l2: 0.00257, Time: 0.17\n",
            "It: 6440, Loss: 3.268e+01, l1: 1.010, l2: 0.00257, Time: 0.17\n",
            "It: 6450, Loss: 1.686e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6460, Loss: 1.864e+01, l1: 1.010, l2: 0.00257, Time: 0.15\n",
            "It: 6470, Loss: 1.688e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6480, Loss: 1.680e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6490, Loss: 1.655e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6500, Loss: 2.138e+01, l1: 1.010, l2: 0.00257, Time: 0.17\n",
            "It: 6510, Loss: 9.041e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6520, Loss: 4.551e+01, l1: 1.010, l2: 0.00257, Time: 0.15\n",
            "It: 6530, Loss: 2.650e+01, l1: 1.010, l2: 0.00257, Time: 0.17\n",
            "It: 6540, Loss: 1.941e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6550, Loss: 1.651e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6560, Loss: 1.641e+01, l1: 1.010, l2: 0.00257, Time: 0.17\n",
            "It: 6570, Loss: 1.608e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6580, Loss: 1.593e+01, l1: 1.010, l2: 0.00257, Time: 0.15\n",
            "It: 6590, Loss: 1.580e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6600, Loss: 1.573e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6610, Loss: 1.565e+01, l1: 1.010, l2: 0.00257, Time: 0.16\n",
            "It: 6620, Loss: 1.557e+01, l1: 1.010, l2: 0.00257, Time: 0.52\n",
            "It: 6630, Loss: 1.549e+01, l1: 1.010, l2: 0.00257, Time: 0.49\n",
            "It: 6640, Loss: 1.542e+01, l1: 1.010, l2: 0.00257, Time: 0.19\n",
            "It: 6650, Loss: 1.534e+01, l1: 1.010, l2: 0.00257, Time: 0.15\n",
            "It: 6660, Loss: 1.527e+01, l1: 1.010, l2: 0.00257, Time: 0.40\n",
            "It: 6670, Loss: 1.519e+01, l1: 1.010, l2: 0.00257, Time: 0.54\n",
            "It: 6680, Loss: 1.512e+01, l1: 1.010, l2: 0.00257, Time: 0.24\n",
            "It: 6690, Loss: 1.524e+01, l1: 1.010, l2: 0.00257, Time: 0.17\n",
            "It: 6700, Loss: 3.929e+01, l1: 1.010, l2: 0.00257, Time: 0.32\n",
            "It: 6710, Loss: 3.880e+01, l1: 1.010, l2: 0.00257, Time: 0.51\n",
            "It: 6720, Loss: 1.898e+01, l1: 1.009, l2: 0.00257, Time: 0.32\n",
            "It: 6730, Loss: 1.582e+01, l1: 1.009, l2: 0.00257, Time: 0.15\n",
            "It: 6740, Loss: 1.502e+01, l1: 1.009, l2: 0.00257, Time: 0.20\n",
            "It: 6750, Loss: 1.563e+01, l1: 1.009, l2: 0.00257, Time: 0.16\n",
            "It: 6760, Loss: 1.492e+01, l1: 1.009, l2: 0.00257, Time: 0.16\n",
            "It: 6770, Loss: 1.465e+01, l1: 1.009, l2: 0.00257, Time: 0.16\n",
            "It: 6780, Loss: 1.455e+01, l1: 1.009, l2: 0.00257, Time: 0.16\n",
            "It: 6790, Loss: 1.447e+01, l1: 1.009, l2: 0.00257, Time: 0.16\n",
            "It: 6800, Loss: 1.438e+01, l1: 1.009, l2: 0.00257, Time: 0.17\n",
            "It: 6810, Loss: 1.431e+01, l1: 1.009, l2: 0.00257, Time: 0.16\n",
            "It: 6820, Loss: 1.424e+01, l1: 1.009, l2: 0.00257, Time: 0.17\n",
            "It: 6830, Loss: 1.417e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 6840, Loss: 1.422e+01, l1: 1.009, l2: 0.00256, Time: 0.17\n",
            "It: 6850, Loss: 3.701e+01, l1: 1.010, l2: 0.00256, Time: 0.16\n",
            "It: 6860, Loss: 4.346e+01, l1: 1.009, l2: 0.00256, Time: 0.18\n",
            "It: 6870, Loss: 2.387e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 6880, Loss: 1.757e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 6890, Loss: 1.515e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 6900, Loss: 1.420e+01, l1: 1.009, l2: 0.00256, Time: 0.17\n",
            "It: 6910, Loss: 1.383e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 6920, Loss: 1.366e+01, l1: 1.009, l2: 0.00256, Time: 0.17\n",
            "It: 6930, Loss: 1.362e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 6940, Loss: 1.419e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 6950, Loss: 4.650e+01, l1: 1.009, l2: 0.00256, Time: 0.15\n",
            "It: 6960, Loss: 3.027e+01, l1: 1.009, l2: 0.00256, Time: 0.17\n",
            "It: 6970, Loss: 1.739e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 6980, Loss: 1.735e+01, l1: 1.009, l2: 0.00256, Time: 0.17\n",
            "It: 6990, Loss: 1.397e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 7000, Loss: 1.330e+01, l1: 1.009, l2: 0.00256, Time: 0.17\n",
            "It: 7010, Loss: 1.331e+01, l1: 1.009, l2: 0.00256, Time: 0.15\n",
            "It: 7020, Loss: 1.318e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 7030, Loss: 1.306e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 7040, Loss: 1.299e+01, l1: 1.009, l2: 0.00256, Time: 0.17\n",
            "It: 7050, Loss: 1.294e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 7060, Loss: 1.288e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 7070, Loss: 1.282e+01, l1: 1.009, l2: 0.00256, Time: 0.15\n",
            "It: 7080, Loss: 1.281e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 7090, Loss: 1.556e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 7100, Loss: 1.084e+02, l1: 1.009, l2: 0.00256, Time: 0.18\n",
            "It: 7110, Loss: 1.386e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 7120, Loss: 1.794e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7130, Loss: 1.588e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7140, Loss: 1.271e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7150, Loss: 1.288e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7160, Loss: 1.253e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7170, Loss: 1.236e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7180, Loss: 1.229e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7190, Loss: 1.223e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7200, Loss: 1.217e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7210, Loss: 1.212e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7220, Loss: 1.206e+01, l1: 1.008, l2: 0.00256, Time: 0.18\n",
            "It: 7230, Loss: 1.201e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7240, Loss: 1.199e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7250, Loss: 1.338e+01, l1: 1.009, l2: 0.00256, Time: 0.16\n",
            "It: 7260, Loss: 7.943e+01, l1: 1.009, l2: 0.00256, Time: 0.18\n",
            "It: 7270, Loss: 2.021e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7280, Loss: 1.904e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7290, Loss: 1.443e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7300, Loss: 1.278e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7310, Loss: 1.184e+01, l1: 1.008, l2: 0.00256, Time: 0.15\n",
            "It: 7320, Loss: 1.169e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7330, Loss: 1.165e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7340, Loss: 1.154e+01, l1: 1.008, l2: 0.00256, Time: 0.19\n",
            "It: 7350, Loss: 1.152e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7360, Loss: 1.210e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7370, Loss: 3.784e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7380, Loss: 1.853e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7390, Loss: 2.091e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7400, Loss: 1.148e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7410, Loss: 1.207e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7420, Loss: 1.173e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7430, Loss: 1.134e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7440, Loss: 1.112e+01, l1: 1.008, l2: 0.00256, Time: 0.16\n",
            "It: 7450, Loss: 1.105e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7460, Loss: 1.101e+01, l1: 1.008, l2: 0.00256, Time: 0.17\n",
            "It: 7470, Loss: 1.099e+01, l1: 1.008, l2: 0.00255, Time: 0.15\n",
            "It: 7480, Loss: 1.121e+01, l1: 1.008, l2: 0.00255, Time: 0.17\n",
            "It: 7490, Loss: 1.947e+01, l1: 1.008, l2: 0.00255, Time: 0.16\n",
            "It: 7500, Loss: 3.977e+01, l1: 1.008, l2: 0.00255, Time: 0.16\n",
            "It: 7510, Loss: 1.242e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7520, Loss: 1.584e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7530, Loss: 1.158e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7540, Loss: 1.074e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7550, Loss: 1.066e+01, l1: 1.007, l2: 0.00255, Time: 0.15\n",
            "It: 7560, Loss: 1.064e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7570, Loss: 1.061e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7580, Loss: 1.050e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7590, Loss: 1.051e+01, l1: 1.007, l2: 0.00255, Time: 0.15\n",
            "It: 7600, Loss: 1.218e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7610, Loss: 4.759e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7620, Loss: 1.560e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7630, Loss: 1.654e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7640, Loss: 1.057e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7650, Loss: 1.117e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7660, Loss: 1.478e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7670, Loss: 4.283e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7680, Loss: 2.020e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7690, Loss: 1.422e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7700, Loss: 1.151e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7710, Loss: 1.004e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7720, Loss: 1.054e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7730, Loss: 1.042e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7740, Loss: 1.212e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7750, Loss: 3.804e+01, l1: 1.007, l2: 0.00255, Time: 0.18\n",
            "It: 7760, Loss: 1.329e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7770, Loss: 1.265e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7780, Loss: 1.094e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7790, Loss: 9.797e+00, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7800, Loss: 1.009e+01, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7810, Loss: 9.672e+00, l1: 1.007, l2: 0.00255, Time: 0.17\n",
            "It: 7820, Loss: 9.885e+00, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7830, Loss: 1.297e+01, l1: 1.007, l2: 0.00255, Time: 0.16\n",
            "It: 7840, Loss: 5.530e+01, l1: 1.007, l2: 0.00255, Time: 0.15\n",
            "It: 7850, Loss: 2.451e+01, l1: 1.006, l2: 0.00255, Time: 0.15\n",
            "It: 7860, Loss: 1.245e+01, l1: 1.006, l2: 0.00255, Time: 0.16\n",
            "It: 7870, Loss: 9.738e+00, l1: 1.006, l2: 0.00255, Time: 0.18\n",
            "It: 7880, Loss: 9.579e+00, l1: 1.006, l2: 0.00255, Time: 0.17\n",
            "It: 7890, Loss: 9.692e+00, l1: 1.006, l2: 0.00255, Time: 0.16\n",
            "It: 7900, Loss: 9.511e+00, l1: 1.006, l2: 0.00255, Time: 0.16\n",
            "It: 7910, Loss: 9.438e+00, l1: 1.006, l2: 0.00255, Time: 0.16\n",
            "It: 7920, Loss: 1.028e+01, l1: 1.006, l2: 0.00255, Time: 0.17\n",
            "It: 7930, Loss: 3.641e+01, l1: 1.006, l2: 0.00255, Time: 0.18\n",
            "It: 7940, Loss: 2.092e+01, l1: 1.006, l2: 0.00255, Time: 0.19\n",
            "It: 7950, Loss: 1.009e+01, l1: 1.006, l2: 0.00255, Time: 0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3seZpCJL3JF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}